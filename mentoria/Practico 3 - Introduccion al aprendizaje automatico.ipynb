{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "### Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2021\n",
    "Búsqueda y Recomendación para Textos Legales\n",
    "\n",
    "Mentor: Jorge E. Pérez Villella\n",
    "\n",
    "# Práctico Introducción al Aprendizaje Automático\n",
    "\n",
    "Integrantes:\n",
    "\n",
    "- Christian Oviedo\n",
    "- Francisco Correa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este práctico es probar distintos modelos de clasificación para evaluar la performance y la exactitud de predicción de cada modelo. \n",
    "\n",
    "* Utilizando el corpus normalizado en el práctico anterior, transformar el texto en vectores numéricos utilizando scikit-learn comparando los 3 modelos de vectorización. Explicar cada uno estos modelos.\n",
    "\n",
    "* Clasificar los documentos por fuero. Trabajaremos con los siguientes modelos de clasificación de la librería scikit-learn: Logistic Regresion, Naive Bayes y SVM. En cada modelo probar distintos hiperparámetros, generar la Matriz de Confusión y la Curva ROC. Explicar los resultados obtenidos.\n",
    "\n",
    "* Determinar y justificar cual es el modelo con mejor performance y predecir el fuero de un documento utilizando el mejor modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fecha de Entrega: 15 de agosto de 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el corpus normalizado en en el práctico anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta clase permite hacer un gridsearch sobre diferentes modelos. Ver http://www.davidsbatista.net/blog/2018/02/23/model_optimization/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_name = 'cleaned_corpus.csv'\n",
    "cleaned_corpus = pd.read_csv(corpus_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dato causa sede ciudad cordoba dependencia juz...</td>\n",
       "      <td>4de122c24ab1606c9d67f4ff9e656143</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>univoco fecha materia revista familia tribunal...</td>\n",
       "      <td>1f9cdcb2c2596656b540c1271fc2d843</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>juzgado juventud violencia familiar 8ª cordoba...</td>\n",
       "      <td>17dcae14592fc6e87680ccb4251d9395</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>auto caratulado a. a. denuncia violencia gener...</td>\n",
       "      <td>4b3ae58648b6267ebb332feec8002588</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>juzg adolescencia violencia familiar 4ta cba s...</td>\n",
       "      <td>1316026beaa1d7e6530bdfe7e54f7b5c</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  dato causa sede ciudad cordoba dependencia juz...   \n",
       "1           1  univoco fecha materia revista familia tribunal...   \n",
       "2           2  juzgado juventud violencia familiar 8ª cordoba...   \n",
       "3           3  auto caratulado a. a. denuncia violencia gener...   \n",
       "4           4  juzg adolescencia violencia familiar 4ta cba s...   \n",
       "\n",
       "                                 id          classifier  \n",
       "0  4de122c24ab1606c9d67f4ff9e656143  Documentos/MENORES  \n",
       "1  1f9cdcb2c2596656b540c1271fc2d843  Documentos/MENORES  \n",
       "2  17dcae14592fc6e87680ccb4251d9395  Documentos/MENORES  \n",
       "3  4b3ae58648b6267ebb332feec8002588  Documentos/MENORES  \n",
       "4  1316026beaa1d7e6530bdfe7e54f7b5c  Documentos/MENORES  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los sets de entrenamiento y de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_corpus['text']  \n",
    "y = cleaned_corpus['classifier']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función recibe una lista de documentos para entrenar (X_train), una lista de documentos para hacer el testing (X_test )del modelo entrenado, y un vectorizer para transformar a vectores los documentos de entrenamiento y prueba. Devuelve dos matrices sparse donde cada fila es un vector que representa un documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(X_train, X_test, vectorizer):\n",
    "    \n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_text_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    return (X_train_vect, X_text_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización con CountVectorizer (tambien conocido como One-hot encoding)\n",
    "Este esquema de vectorización es el más simple y básico. Se genera un vector que representa todas las palabras del corpus. Cada documento es representado como una instancia del vector anterior indicando la cantidad de veces que aparece cada palabra. Notar que este modelo de vectorización esta sesgado para el caso en que tengamos palabras poco frecuentes pero muy significativas para clasificar documentos y también para palabras que aparezcan 'mucho', pero que aparezca en todos los documentos. En el último caso, si tratamos de diferenciar los documentos en base a las palabras que los componen, que las palabras aparezcan en todos ellos, no aporta información.\n",
    "\n",
    "Como se explica en el parrafo anterior, es el modelo mas sencillo, generando por cada un token un vector de dimensionalidad exacta a la longitud del vocabulario con un 1 en su dimension y 0 en todos los otros lugares.\n",
    "\n",
    "![One-hot](./images/one-hot.png)\n",
    "\n",
    "Para trabajar con matrices mas pequeñas scikit-learn en su modelo CountVectorizer() nos retorna matrices esparsas (es posible tambien obtener la matriz dispersa u \"original\" correspondiente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 15696)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_vect , X_test_vect = get_vectors(X_train, X_test, count_vect)\n",
    "\n",
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "Cantidad de documentos:162, Cantidad de dimensiones por documento: 15696 \n",
      "X_test\n",
      "Cantidad de documentos:81, Cantidad de dimensiones por documento: 15696 \n"
     ]
    }
   ],
   "source": [
    "print (\"X_train\")\n",
    "print (f\"Cantidad de documentos:{X_train_vect.shape[0]}, Cantidad de dimensiones por documento: {X_train_vect.shape[1]} \")\n",
    "\n",
    "print (\"X_test\")\n",
    "print (f\"Cantidad de documentos:{X_test_vect.shape[0]}, Cantidad de dimensiones por documento: {X_test_vect.shape[1]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización con HashingVectorizer\n",
    "\n",
    "El método anterior, aunque es sencillo, su implemetacion guarda el vocabulario \"in-memory\" en forma de diccionario, lo cual puede ser causante de un gran consumo de memoria si el dataset es extenso.\n",
    "\n",
    "A resolver este problema viene el siguiente método: HashingVectorizer. Este método convierte una serie de documentos a una matriz de ocurrencias de tokens (como CountVectorizer) pero aplicando a cada feature una funcion de hash y usando este valor como indice en lugar de usar los indices \"normales\" de forma asociativa. Usa el algoritmo conocido como \"hashing trick\". More info: https://en.wikipedia.org/wiki/Feature_hashing.\n",
    "\n",
    "Este método presenta las ventajas de permitir escabilidad en terminos de uso de memoria, facil uso de pickle para los vectores y/0 matrices resultantes y la posibilidad de usarlo en \"fit\" parciales (mas conocido como streaming, de aqui la posibilidad de trabajar con datasets enormes). \n",
    "\n",
    "Aunque existen algunas desventajas como que pueden existir \"colisiones de hashes\" (features distintas mapeadas a indices iguales) siendo que el numero de features es un parametro y el equipo de desarrollo deberia elegir un numero fijo, esto no es en si algo malo, siendo que dependiendo del caso escoger un n_features mas pequeño reduciria la complejidad de nuestro modelo. Y tambien existe el problema de que la conversion de un token a hash es unidireccional lo cual puede ser un problema si luego del entramiento del modelo se quisiera inspeccionar las features que serian mas importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 3000) (81, 3000)\n",
      "[[ 0.          0.          0.         ...  0.          0.03912554\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.0058243  ...  0.          0.0058243\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.0493147\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.01537688\n",
      "   0.        ]\n",
      " [ 0.          0.          0.00494257 ...  0.          0.06919594\n",
      "   0.        ]\n",
      " [ 0.          0.          0.00982424 ...  0.          0.03929698\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "n_features = 3000\n",
    "hash_vect = HashingVectorizer(n_features=n_features)\n",
    "X_train_hash , X_test_hash = get_vectors(X_train, X_test, hash_vect)\n",
    "\n",
    "print(X_train_hash.shape, X_test_hash.shape)\n",
    "print(X_train_hash.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización con TfidfVectorizer\n",
    "Cuando vimos el método CountVectorizer, vimos que no es suficiente únicamente contar la cantidad de veces que aparece una palabra en un documento, puesto que no es lo mismo que esa palabra aparezca en el resto de los documentos (en este caso, la palabra no brinda información relevante) a que aparezca en un número reducido de documentos (en este caso la palabra si brinda información relevante.)\n",
    "Es por eso que es necesario contar con algún método que permita hacer este tipo de distinciones a la hora de expresar documentos como vectores.\n",
    "\n",
    "El método TF-IDF (Term Frequency – Inverse Documento Frequency) busca generar vectores que indican no solamente cuanto aparece una palabra en un documento, sino que tan frecuente es esa palabra en el resto de los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(palabra,documento) =  $\\frac{\\textrm{Número de veces que la palabra aparece en el documento}}{\\textrm{Número de palabras diferentes en el documento}}$\n",
    "\n",
    "\n",
    "DF(palabra,documentos) =  $\\frac{\\textrm{Cantidad de documentos que tienen la palabra}}{\\textrm{cantidad de documentos}}$\n",
    "\n",
    "\n",
    "IDF(palabra,documentos) = $ log ({\\frac{\\textrm{cantidad de documentos}}{\\textrm{Cantidad de documentos que tienen la palabra}}})$\n",
    "\n",
    "Notar que en IDF, cuando la cantidad de documentos que tienen la palabra, se acerca a la cantidad de documentos, el resultado de la división se acerca a 1 y por consiguiente, el logartimo a 0.\n",
    "\n",
    "**TF - IDF = (palabra, documentos, documento) = TF (palabra, documento) $\\times$ IDF (palabra, documentos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn ofrece 2 maneras de realizar esto: TfidfVectorizer y TfidfTransformer, el primero se aplica sobre la serie de documentos. Dependiendo del problema, si se necesitara obtener el conteo de frecuencia de tokens para realizar otras tareas entonces ir por la opcion CountVectorizer+TfidfTransformer es mejor idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 15696)\n",
      "(15696,)\n"
     ]
    }
   ],
   "source": [
    "# Using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf , X_test_tfidf = get_vectors(X_train, X_test, vectorizer)\n",
    "\n",
    "print(X_train_tfidf.shape) \n",
    "\n",
    "# Using TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "\n",
    "X_train_tfidf_transformer = transformer.fit(X_train_vect)\n",
    "\n",
    "print(X_train_tfidf_transformer.idf_.shape) # Solo obteniendo los valores idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "Cantidad de documentos:162, Cantidad de dimensiones por documento: 15696 \n",
      "X_test\n",
      "Cantidad de documentos:81, Cantidad de dimensiones por documento: 15696 \n"
     ]
    }
   ],
   "source": [
    "print (\"X_train\")\n",
    "print (f\"Cantidad de documentos:{X_train_tfidf.shape[0]}, Cantidad de dimensiones por documento: {X_train_tfidf.shape[1]} \")\n",
    "\n",
    "print (\"X_test\")\n",
    "print (f\"Cantidad de documentos:{X_test_tfidf.shape[0]}, Cantidad de dimensiones por documento: {X_test_tfidf.shape[1]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables X_train_counts y X_test_counts se usan para todos los cálculos que siguen. Estas variables las igualamos a las variables que tienen los resultados de TF – IDF por ser el mejor método de vectorización de los tres analizados. En el caso de querer correr la notebook con el resultado de CountVectorizer, o Hash, descomentar las celdas correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts  = X_train_tfidf\n",
    "X_test_counts = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_counts  = X_train_vect\n",
    "#X_test_counts = X_test_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación usando diferentes modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC\n",
    "\n",
    "\n",
    "Se puede utilizar un gráfico AUC ROC (Área bajo la curva de características operativas del receptor) para visualizar el rendimiento de un modelo entre la sensibilidad y la especificidad. La sensibilidad se refiere a la capacidad de identificar correctamente las entradas que pertenecen a la clase positiva. La especificidad se refiere a la capacidad de identificar correctamente las entradas que pertenecen a la clase negativa. Dicho de otra manera, una gráfica AUC ROC puede ayudar a identificar qué tan bien su modelo es capaz de distinguir entre clases.\n",
    "\n",
    "\n",
    "En los problemas del mundo real, a menudo hay una superposición entre las clases, lo que significa que detectar todos los verdaderos negativos y verdaderos positivos puede ser desafío muchas veces de imposible solución. Se muestra a continuación una ilustración de lo que se esta comentando:\n",
    "\n",
    "\n",
    "<img src=\"images/ROC_curve.png\">\n",
    "\n",
    "\n",
    "\n",
    "Notar que dependiendo donde se ubique el umbral de predicción, cambiará el número de TP, TN, FP y FN. Notar también que en el gráfico anterior, las distribuciones se solapan (lo que sucede con frecuencia en problemas de la vida real), lo que trae como consecuencia, tener inevitablemente FN y FP.\n",
    "\n",
    "El tipo de problemática que quiera resolver, es el que indicará hacia donde muevo el umbral. Supongamos por ejemplo que lo que estamos tratando de clasificar es si un paciente tiene cáncer o no. Es claro que en este ejemplo, no quiero tener falsos negativos (FNwww.www). No es aceptable que a una persona que tiene cáncer, le de un diagnóstico en el cual indica que esta sana. En este caso, voy a mover el umbral de predicción hacia la izquierda de manera tal que no exista la posibilidad de generar falsos negativos (FN). Al mover el umbral de esta manera, voy a aumentar inevitablemente la cantidad de falsos positivos (FP), los cuales luego puedo descartar con estudios más específicos.\n",
    "\n",
    "Volviendo gráfico AUC ROC, una puntuación AUC de 1 significa que el modelo puede distinguir con precisión entre las dos clases el 100% del tiempo, es decir, estamos frente a un clasificador ideal. Una puntuación de 0,5 significa que el modelo no puede determinar entre las dos clases y, en esencia, está adivinando. La curva ROC es la gráfica de la tasa de verdaderos positivos del modelo frente a la tasa de falsos positivos.\n",
    "\n",
    "\n",
    "\n",
    "$\\textrm{TPR} =  \\frac{\\textrm{TP}} {{\\textrm{TP}}➕{\\textrm{FN}} }$\n",
    "\n",
    "$\\textrm{FPR} =  \\frac{\\textrm{FP}} {{\\textrm{FP}}➕{\\textrm{TN}} }$\n",
    "\n",
    "\n",
    "De lo antes indicado, entonces al momento de evaluar los modelos de clasificación, buscaremos o nos quedaremos con aquel modelo y los correspondientes híper parámetros para los cuales el área bajo la curva ROC sea lo más cercana a 1.\n",
    "\n",
    "<img src=\"images/ROC_curve_values.png\">\n",
    "\n",
    "La clasificación que se solicita en la mentoria, es una clasificación multi clase, es por ello que debemos extender el concepto de curvas ROC a curvas ROC para clasificaciones multi clases\n",
    "\n",
    "Lo que se estuvo presentando hasta el momento esta orientado a clasificaciones binarias. Como se puede hacer para llevar o reutilizar lo antes mencionado en clasificaciones multi clases. Una estrategia para lograr esto, es que las curvas ROC se pueden trazar con la metodología de usar una clase frente al resto. Utilizando uno contra el resto para cada clase, se tendrá el mismo número de curvas que clases. La puntuación AUC también se puede calcular para cada clase individualmente.\n",
    "\n",
    "\n",
    "<img src=\"images/ROC_curve_multiclass.png\">\n",
    "\n",
    "El componente que utilizaremos para realizar la Curva ROC para clasificaciones multi clases, es el provisto por  **yellowbrick** (https://www.scikit-yb.org/en/latest/api/classifier/rocauc.html)\n",
    "\n",
    "\n",
    "ROC Multiclass: https://medium.com/swlh/how-to-create-an-auc-roc-plot-for-a-multiclass-model-9e13838dd3de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **test_model** recibe un modelo de clasificación (por ejemplo Naive Bayes, Regresión Logística, etc ), los sets de entrenamiento y testing, y muestra:\n",
    "\n",
    "\n",
    "-\tLa métricas: precisión, recall, f1-score\n",
    "-\tLa matriz de confusión\n",
    "-\tCurca ROC Multiclase y el AUC correspondiente\n",
    "\n",
    "Este método usa el método plot_ROC_curve para poder visualizar la curva ROC multiclase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-930c00d2cb65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_ROC_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmacro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Creating visualization with the readable labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "def plot_ROC_curve(model, xtrain, ytrain, xtest, ytest , ax , macro = True, micro = True , per_class = True):\n",
    "\n",
    "    # Creating visualization with the readable labels\n",
    "    visualizer = ROCAUC(estimator = model , ax = ax , macro = macro, micro = micro , per_class = per_class)\n",
    "                                        \n",
    "    # Fitting to the training data first then scoring with the test data                                    \n",
    "    visualizer.fit(xtrain, ytrain)\n",
    "    visualizer.score(xtest, ytest)\n",
    "    visualizer.show()\n",
    "    \n",
    "    #return visualizer\n",
    "\n",
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test ):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_test_pred ))\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.grid(False)\n",
    "    ax.set_title('Confusion Matrx')\n",
    "\n",
    "    disp =metrics.plot_confusion_matrix(model, X_test, y_test, display_labels= [\"FAMILIA\" ,\"LABORAL\" , \"MENORES\" , \"PENAL\" ], ax = ax)\n",
    "    \n",
    "    #disp =metrics.plot_confusion_matrix(model, X_test, y_test, display_labels= [\"FAMILIA\" ,\"LABORAL\" , \"MENORES\" , \"PENAL\" ])\n",
    "    \n",
    "\n",
    "    #disp.confusion_matrix\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    ax1.set_title('ROC')\n",
    "        \n",
    "    plot_ROC_curve(model = model, xtrain = X_train, ytrain = y_train, xtest = X_test, ytest = y_test , ax = ax1 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seteamos el seed para que todos los experimentos sean repetibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos y los híper paramétros mostrados a continuación, provienen de los resultados obtenidos en el apartado **Anexo**, punto *Optimización de modelos*.  Ahí se pueden observar los modelos que se probaron, los híper parámetros utilizados y los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltest = linear_model.LogisticRegression(multi_class= 'ovr',solver = 'liblinear', random_state= seed)\n",
    "\n",
    "test_model(ltest,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear' , random_state = seed)\n",
    "\n",
    "test_model(lm,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "test_model(nb,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = svm.SVC(kernel='rbf' , random_state = seed)\n",
    "\n",
    "test_model(rbf,X_train_counts, y_train, X_test_counts, y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = svm.SVC(kernel='poly', degree=3 , random_state = seed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(poly,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "En líneas generales se observa un buen desempeño de todos los modelos, salvo el MultinomialNB. Quizás este buen desempeño se producto de la poca cantidad de documentos y que además los documentos hallan sido generados por el mismo grupo de persona en cada fuero. Es decir, por ejemplo en el fuero penal, quizás los fallos pertenecen al mismo juez y han sido redactados por la misma persona. Esto indicaría un fuerte sesgo en el set de datos. Sugerimos contar con más fallos para poder aumentar el el set de datos y al mismo tiempo darle más variabilidad al mismo.\n",
    "\n",
    " Si bien dentro de los modelos de clasificación solicitados, no estaba indicado RandomForest, lo hemos agregado al mismo en el Anexo. De todos los modelos, Random Forest fue el que mejor desempeño tuvo. \n",
    "\n",
    "Los mejores modelos y los respectivos híper parámetros encontrados son:\n",
    "\n",
    "### RandomForest:\n",
    "\n",
    "-\tcriterion: entropy\n",
    "-\tn_estimadors: 100\n",
    "  \n",
    "\n",
    "### RandomForest:\n",
    "\n",
    "-\tcriterion: gini\n",
    "-\tn_estimadors: 100\n",
    "\n",
    "### SVC:\n",
    "\n",
    "-\tkernel: poly\n",
    "-\tdegree: 2\n",
    "\n",
    "### SVC:\n",
    "\n",
    "-\tkernel: rbf\n",
    "\n",
    "### SVC:\n",
    "\n",
    "-\tkernel: linear\n",
    "\n",
    "### SVC:\n",
    "\n",
    "-\tkernel: sigmoid\n",
    "\n",
    "\n",
    "### LogisticRegression\n",
    "\n",
    "\n",
    "-\tC: 1.0\n",
    "-\tmulti_class: ovr\n",
    "-\tpenalty: l2\n",
    "-\tsolver: liblinear\n",
    "\n",
    "En el apartado **Anexo**, punto *Optimización de modelos*, se puede observar los modelos que se probaron, los híper parámetros utilizados y los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = 30\n",
    "print (f\"Label del documento {y_test.values[document_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El valor por defecto de n_estimatores es 100\n",
    "rf_entropy = RandomForestClassifier(criterion = 'entropy') \n",
    "rf_entropy.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicción {rf_entropy.predict(X_test_counts[document_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gini = RandomForestClassifier(criterion = 'gini') \n",
    "rf_gini.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicción {rf_gini.predict(X_test_counts[document_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_poly = svm.SVC(kernel = \"poly\" , degree = 3 )\n",
    "svc_poly.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicción {svc_poly.predict(X_test_counts[document_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf = svm.SVC(kernel = \"rbf\" )\n",
    "svc_rbf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicción {svc_rbf.predict(X_test_counts[document_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una implementación de gridsearch con cross validation, que permite pasar diferentes modelos de sickit-learn a ajustar. \n",
    "La idea es que este método nos permita hacer pruebas de manera sencilla de diferentes métodos con diferentes parámetros. Luego en base a estos resultados, elegimos que modelos y parámetros presentar en el apartado * Clasificación usando diferentes modelos*\n",
    "\n",
    "A la función **train_modelos** se le pasan:\n",
    "-\t Dos diccionarios: los modelos y los parámetros.\n",
    "-\t Los sets de entrenamiento y test\n",
    "-\t La cantidad de folds\n",
    "\n",
    "El método hace el entrenamiento de todos los modelos en base a los parámetros que se le indican y usando el CV indicado. La función no calcula por el momento cual es el mejor modelo e hiper parámetros correspondientes. Esto se hace por medio de una inspección visual. En futuras versiones se puede implementar la función última descripta. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa a esta implementación puede ser la indicada en http://www.davidsbatista.net/blog/2018/02/23/model_optimization/ . Preferimos implementar una versión propia para poder entender más profundamente los conceptos vistos en la diplomatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = {\n",
    "    'RandomForset': RandomForestClassifier(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'SVM_01': svm.SVC(),\n",
    "    'SVM_02': svm.SVC(),\n",
    "    'LogisticRegressionClassifier': linear_model.LogisticRegression() ,\n",
    "    'LogisticRegressionClassifier_01': linear_model.LogisticRegression()\n",
    "    \n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'RandomForset': {\"n_estimators\" : [100] , \"criterion\" : [\"gini\", \"entropy\"]},\n",
    "    'LogisticRegressionClassifier': { \"solver\":[\"liblinear\" , \"sag\", \"saga\",\"lbfgs\"], \"multi_class\":[\"ovr\"], \"penalty\":[\"l2\" ] , \"C\": [1.0,0.7]  } ,\n",
    "    'LogisticRegressionClassifier_01': { \"solver\":[\"liblinear\" ], \"multi_class\":[\"ovr\"], \"penalty\":[\"l2\",\"l1\"] , \"C\": [1.0,0.7,0.2]  } ,\n",
    "    'SVM_01':{\"kernel\" :['poly'] , \"degree\" : [2,3,4,5] } ,\n",
    "    'SVM_02':{\"kernel\" :['linear', 'rbf', 'sigmoid']  } ,\n",
    "    'MultinomialNB':{\"alpha\" :[1.0] }\n",
    "} \n",
    "\n",
    "\n",
    "models1T = {\n",
    "    'SVM_01': svm.SVC(),\n",
    "  \n",
    "}\n",
    "\n",
    "params1T = {\n",
    "      'SVM_01':{\"kernel\" :['linear', 'poly', 'rbf', 'sigmoid'] , \"degree\" : [3] } ,\n",
    "    \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "\n",
    "\n",
    "\n",
    "def roc_auc_score_macro(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    roc_auc = roc_auc_score(actual_class, pred_class, average = average , multi_class ='ovr')\n",
    " \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "  #creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    #creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    #marking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    #using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average , multi_class ='ovr')\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict\n",
    "\n",
    "#def train_model(model, folds_index, X_train, Y_train):\n",
    "\n",
    "def generate_model_params(model_params):\n",
    "    \n",
    "    allNames = sorted(model_params)\n",
    "    combinations = it.product(*(model_params[Name] for Name in allNames))\n",
    "    return (list(combinations) , allNames)\n",
    "\n",
    "\n",
    "def train_model(model, params_names, param_combination, folds_index, X_train, Y_train , X_test, Y_test , output_dict = True , random_state = None):\n",
    "    \n",
    "    param_combination = list(param_combination)\n",
    "    print (\"train model\")\n",
    "    print (f\"{model} {params_names} {param_combination}\")\n",
    "   \n",
    "    \n",
    "    cloned_model = deepcopy(model)\n",
    "    \n",
    "    \n",
    "    for param_name , param_value in zip(params_names,param_combination ):\n",
    "        #print (f\"{param_name} =  {param_value}\")\n",
    "        setattr(cloned_model , param_name , param_value)\n",
    "\n",
    "    if type(random_state) == int:\n",
    "        setattr(cloned_model , \"random_state\" , random_state)\n",
    "        \n",
    "    print (cloned_model)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for train_index, test_index in folds_index:\n",
    "   \n",
    "        cloned_model_tmp = deepcopy(cloned_model)\n",
    "        #print (f\"{train_index}\")\n",
    "        #print (f\"{test_index}\")\n",
    "    \n",
    "    \n",
    "    #X_train, X_test, y_train, y_test\n",
    "    \n",
    "        # Se hace el split en base a los CV. Se obtienen los datos de X_train y de X_test con sus respectivos Y\n",
    "        X_train_tmp, X_test_tmp = X_train[train_index], X_train[test_index]\n",
    "        \n",
    "        y_train_tmp, y_test_tmp = Y_train[train_index], Y_train[test_index] \n",
    "    \n",
    "        cloned_model_tmp.fit(X_train_tmp,y_train_tmp)\n",
    "       \n",
    "    \n",
    "        y_test_val_pred = cloned_model_tmp.predict(X_test_tmp)\n",
    "        \n",
    "        train_result = metrics.classification_report(y_test_tmp, y_test_val_pred , output_dict = output_dict )\n",
    "        \n",
    "        print(train_result)\n",
    "        \n",
    "        \n",
    "        #roc_result = roc_auc_score(y_true = y_test_tmp, y_score = y_test_val_pred , multi_class = \"ovr\")\n",
    "        \n",
    "        roc_result = roc_auc_score_multiclass(actual_class=y_test_tmp, pred_class=y_test_val_pred)\n",
    "        #roc_result_macro = roc_auc_score_macro(actual_class=y_test_tmp, pred_class=y_test_val_pred)\n",
    "        \n",
    "        \n",
    "        results.append ((f\"{model}\",\"Train\" , f\"{params_names }\", train_result , roc_result , f\"{param_combination}\" ))\n",
    "    \n",
    "    \n",
    "    cloned_model_tmp = deepcopy(cloned_model)\n",
    "    \n",
    "    \n",
    "    cloned_model_tmp.fit(X_train,Y_train)\n",
    "        \n",
    "    y_test_pred = cloned_model_tmp.predict(X_test)\n",
    "    \n",
    "    test_result = metrics.classification_report(Y_test, y_test_pred , output_dict = output_dict )\n",
    "    \n",
    "    #roc_result = roc_auc_score(y_true = Y_test, y_score = y_test_pred , multi_class = \"ovr\")\n",
    "    roc_result = roc_auc_score_multiclass(actual_class=Y_test, pred_class=y_test_pred)\n",
    "    #roc_result_macro = roc_auc_score_macro(actual_class=y_test_tmp, pred_class=y_test_val_pred)\n",
    "        \n",
    "    results.append ((f\"{model}\",\"Test\", f\"{params_names} \", test_result , roc_result , f\"{param_combination}\" ))\n",
    "    \n",
    "    print(\"Test\")\n",
    "    print(test_result)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    \n",
    "\n",
    "def train_models(X_train,Y_train,X_test, Y_test, cv=5,shuffle=True, models=None ,params=None , output_dict = True , random_state = None):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    kf = KFold(n_splits=cv, random_state=random_state, shuffle=shuffle )\n",
    "   \n",
    "    \n",
    "    folds_index = [(train_index, test_index) for train_index, test_index in kf.split(X_train)  ]\n",
    "\n",
    "    for param_model in params.keys():\n",
    "    \n",
    "        params_combination, params_names = generate_model_params(params.get(param_model))\n",
    "        #print (f\"Modelo a ejecutar: {param_model}, parámetros a probar: {params_combination} , nombre de los parámetros: {params_names} \")\n",
    "        \n",
    "        for param_combination in params_combination:\n",
    "            #print (f\"{param_model}: {param_combination} \")\n",
    "            \n",
    "            model_result = train_model(model = models.get(param_model),params_names = params_names, param_combination = param_combination, folds_index = folds_index, X_train = X_train, Y_train = Y_train , X_test = X_test, Y_test = Y_test , output_dict = output_dict , random_state = random_state )     \n",
    "            \n",
    "            results.extend(model_result)\n",
    "    return results        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función arma un data frame con el resultado de los entrenamientos. Notar que para calcular el ROC_AUC, se hace una suma de los valores ponderados del ROC por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataFrame(results, y_test):\n",
    "    \n",
    "    counter = Counter(y_test)\n",
    "    total = counter['Documentos/FAMILIA'] + counter['Documentos/LABORAL'] + counter['Documentos/MENORES'] + counter['Documentos/PENAL']\n",
    "    familia = counter['Documentos/FAMILIA'] / total\n",
    "    laboral = counter['Documentos/LABORAL'] / total\n",
    "    menores = counter['Documentos/MENORES'] / total\n",
    "    penal = counter['Documentos/PENAL'] / total\n",
    "    \n",
    "    print (\"Ponderado fuero\")\n",
    "    print (f\"familia: {familia}, laboral: {laboral}, menores: {menores}, penal: {penal} \")\n",
    "    \n",
    "    filtered_values =  []\n",
    "    columns = [\"modelo\", \"modo\" , \"parametros\" , \"valores\" , \"accuracy\", \"precision\" , \"recall\" , \"f1-score\" , \"roc_penal\", \"roc_familia\" ,\"roc_laboral\" , \"roc_menores\"]\n",
    "    for result in results:\n",
    "        #print (f\"{result[0]} {result[1]} {result[2]} {result[3]['macro avg']} \\n\")\n",
    "        filtered_values.append((result[0], result[1] , result[2] , result[5] , result[3]['accuracy'], result[3]['macro avg']['precision'] , result[3]['macro avg']['recall'] ,  result[3]['macro avg']['f1-score'] , result[4][\"Documentos/PENAL\"] , result[4][\"Documentos/FAMILIA\"] , result[4][\"Documentos/LABORAL\"] , result[4][\"Documentos/MENORES\"]))\n",
    "\n",
    "    df= pd.DataFrame(data = filtered_values , columns = columns)\n",
    "    \n",
    "    df[\"roc_ponderado\"] = (df[\"roc_penal\"] * penal + df[\"roc_familia\"] * familia + df[\"roc_laboral\"] * laboral + df[\"roc_menores\"] * menores)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = train_models(X_train= X_train_counts, Y_train =y_train.values ,  X_test = X_test_counts, Y_test = y_test.values,  models = models1 , params = params1 , cv=5 , output_dict = True , random_state = seed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_logistic = toDataFrame(results , y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos los modelos (y los parámetros utilizados) según diferentes métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy y f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_logistic[result_logistic[\"modo\"] ==\"Test\"].sort_values(by=['accuracy','f1-score'] , ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_logistic.sort_values(by=['roc_promedio','precision'] , ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el modelo de clasificación random forest no fue solicitado, lo agregamos debido a que los métodos desarrollados nos permiten de una forma sencilla entrenar modelos y visualizar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b4453e1f1703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandomForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_model' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "randomForest = RandomForestClassifier(criterion=\"entropy\" , random_state = seed)\n",
    "test_model(randomForest,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3b501cd76ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandomForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(criterion=\"gini\" , random_state = seed)\n",
    "test_model(randomForest,X_train_counts, y_train, X_test_counts, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros modelos de vectorizacion: word2vec\n",
    "\n",
    "En el mundo de los word embeddings el actual standard de-facto es este modelo de vectorizacion conocido como \"word2vec\". Scikit-learn no ofrece este metodo pero creimos importante al menos nombrarlo en este practico siendo que es una herramienta de amplio uso en el mundo de NLP actualmente.\n",
    "Fue creado por Tomas Mikolov en 2013 (en ese momento empleado de Google). Word2vec es un conjunto de redes neuronales entrenados para reconstruir el contexto linguistico de las palabras.\n",
    "\n",
    "Cabe resaltar que el input de este metodo es igual a los anteriores: el corpus generado desde una serie de documentos.\n",
    "\n",
    "En metodos como CountVectorizer, se crean espacios n-dimensionales donde n es el tamaño del vocabulario, por lo cual cada palabra tomaria lugar en cada dimesion, haciendo a cada palabra independiente. Eso quiere decir que \"bueno\" y \"genial\" estan a la misma distancia (o significan lo mismo) que \"perro\" por ej, lo cual no es correcto. El objetivo es \"agrupar\" palabras con contexto similar en posiciones cercanas (tendiendo la similitud de coseno a 1, o sea, el angulo entre estos vectores es cercano a 0).\n",
    "\n",
    "![One-hot](./images/cos-sim.png)\n",
    "\n",
    "Word2vec resuelve esto usando una de los 2 siguientes arquitecturas de redes neuronales:\n",
    "- Skipgram (generalizacion de n-grams): En este caso el input del modelo es la palabra a predecir y el modelo (el modelo interno de w2v) se encarga de retornar el contexto de la misma. \n",
    "- CBOW (Continuous bag-of-words): Este caso es al reves del anterior, el input del modelo interno es el contexto de la palabra a predecir.\n",
    "\n",
    "![One-hot](./images/cbow-sg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos enfoques obviamente presentan sus ventajas y desventajas, pero en resumidas cuentas se podria decir que:\n",
    "- CBOW tiene una mejor \"accuracy\" con palabras frecuentes y es bastante mas performante en terminos de tiempo que skip-gram.\n",
    "- Skip-gram funciona mejor con menores cantidades de datos entrenados (por lo cual es menos performante en tiempo) y ofrece mejor accuracy para palabras \"raras\" o no tan frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python es posible usar este metodo de word embedding con la ayuda de la libreria 'gensim'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos] *",
   "language": "python",
   "name": "conda-env-diplodatos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
