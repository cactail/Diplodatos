{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "### Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2021\n",
    "Búsqueda y Recomendación para Textos Legales\n",
    "\n",
    "Mentor: Jorge E. Pérez Villella\n",
    "\n",
    "# Práctico Análisis y Visualización\n",
    "\n",
    "Integrantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "* Generar un corpus con todos los documentos. \n",
    "\n",
    "* Dividir el corpus en tokens, graficar el histograma de frecuencia de palabras demostrando la ley Zipf. \n",
    "\n",
    "* Analizar palabras más frecuentes y menos frecuentes. Seleccionar 5 documentos de cada fuero y realizar el mismo análisis. ¿Se repiten las palabras? \n",
    "\n",
    "* Hacer lo mismo con n-gramas.\n",
    "\n",
    "* Visualizar la frecuencia de palabras en una nube de palabras.\n",
    "\n",
    "* Elaborar una breve conclusión de lo encontrado\n",
    "\n",
    "Fecha de Entrega: 6 de junio de 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar un corpus con todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c anaconda spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.examples import sentences\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd \n",
    "import shutil\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_nlp = spacy.load(\"es_core_news_sm\")\n",
    "spacy_nlp = spacy.load(\"es_core_news_md\") \n",
    "\n",
    "spacy_nlp.vocab[\"\\n\"].is_stop = True\n",
    "spacy_nlp.vocab[\" \\n\"].is_stop = True\n",
    "spacy_nlp.vocab[\"y\"].is_stop = True\n",
    "spacy_nlp.vocab[\"a\"].is_stop = True\n",
    "spacy_nlp.vocab[\"o\"].is_stop = True\n",
    "spacy_nlp.vocab[\" \"].is_stop = True\n",
    "spacy_nlp.vocab[\"  \"].is_stop = True\n",
    "spacy_nlp.vocab[\"\\x0c\"].is_stop = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/MENORES\n",
      "Documentos/PENAL\n",
      "Documentos/FAMILIA\n",
      "Documentos/LABORAL\n"
     ]
    }
   ],
   "source": [
    "root_path = \"Documentos\"\n",
    "\n",
    "directories = [x[0] for x in os.walk(root_path)]\n",
    "\n",
    "directories.pop(0)\n",
    "\n",
    "for directory in directories:\n",
    "    print (directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_iterator(paths):\n",
    "    for p in paths:\n",
    "        print(\"yielding\")\n",
    "        yield p.open(\"r\").read(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus_df(directories):\n",
    "    \n",
    "    for directory in directories:\n",
    "        print(directory)\n",
    "        file_list = glob.glob(os.path.join(os.getcwd(), directory, \"*.txt\"))\n",
    "        #file_list = glob.glob(os.path.join(os.getcwd(), directory, \"*.no\"))\n",
    "\n",
    "        for file_path in file_list:\n",
    "            #print(f\"Archivo: {file_path}\")\n",
    "        \n",
    "            with open(file_path, 'r') as reader:\n",
    "                line = reader.readline()\n",
    "                while line != '':\n",
    "                    line = reader.readline()\n",
    "                    yield line.lower()\n",
    "        #with open(file_path ,buffering=100 , encoding='utf-8' , errors='replace') as f_input:\n",
    "        #        yield f_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir el corpus en tokens, graficar el histograma de frecuencia de palabras demostrando la ley Zipf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_words(directory): \n",
    "    \n",
    "    docs = spacy_nlp.pipe(generate_corpus_df([directory]), batch_size=50 , n_process=4  ,disable=[\"tok2vec\", \"tagger\",  \"attribute_ruler\", \"lemmatizer\"]  )\n",
    "    words = [word.text for token in docs for word in token if not word.is_stop and not word.is_punct]\n",
    "    return (words,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/MENORES\n"
     ]
    }
   ],
   "source": [
    "(words_menores,docs_menores) = get_words(directories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/PENAL\n"
     ]
    }
   ],
   "source": [
    "(words_penal,docs_penal) = get_words(directories[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/FAMILIA\n"
     ]
    }
   ],
   "source": [
    "(words_familia,docs_familia) = get_words(directories[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/LABORAL\n"
     ]
    }
   ],
   "source": [
    "(words_laboral,docs_laboral) = get_words(directories[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_ocrruence(words):\n",
    "    \n",
    "    word_freq = Counter(words)\n",
    "    return word_freq.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_limit_commond_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_menores = get_words_ocrruence(words_menores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fs', 1006),\n",
       " ('niño', 939),\n",
       " ('art', 628),\n",
       " ('derechos', 627),\n",
       " ('sra', 605),\n",
       " ('ley', 589),\n",
       " ('familia', 589),\n",
       " ('niña', 542),\n",
       " ('m.', 500),\n",
       " ('medida', 421),\n",
       " ('autos', 401),\n",
       " ('situación', 388),\n",
       " ('familiar', 385),\n",
       " ('derecho', 376),\n",
       " ('r.', 347),\n",
       " ('relación', 341),\n",
       " ('fecha', 334),\n",
       " ('protección', 333),\n",
       " ('sr', 322),\n",
       " ('f.', 295)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_menores(default_limit_commond_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_penal = get_words_ocrruence(words_penal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('expediente', 1289),\n",
       " ('penal', 1245),\n",
       " ('nro', 1243),\n",
       " ('n°', 1094),\n",
       " ('tribunal', 1048),\n",
       " ('s.', 1001),\n",
       " ('art', 904),\n",
       " ('pena', 904),\n",
       " ('vocal', 834),\n",
       " ('nº', 817),\n",
       " ('f.', 759),\n",
       " ('imputado', 745),\n",
       " ('sala', 718),\n",
       " ('sentencia', 642),\n",
       " ('ff', 629),\n",
       " ('juicio', 588),\n",
       " ('caso', 578),\n",
       " ('ley', 561),\n",
       " ('recurso', 549),\n",
       " ('vta', 534)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_penal(default_limit_commond_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_familia = get_words_ocrruence(words_familia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fs', 3193),\n",
       " ('art', 2096),\n",
       " ('recurso', 1625),\n",
       " ('fecha', 1618),\n",
       " ('ley', 1525),\n",
       " ('familia', 1429),\n",
       " ('apelación', 1292),\n",
       " ('cuota', 1224),\n",
       " ('señora', 1192),\n",
       " ('alimentaria', 1186),\n",
       " ('señor', 1065),\n",
       " ('autos', 1063),\n",
       " ('m.', 959),\n",
       " ('tribunal', 950),\n",
       " ('a.', 935),\n",
       " ('mil', 932),\n",
       " ('resolución', 906),\n",
       " ('derecho', 903),\n",
       " ('caso', 864),\n",
       " ('costas', 848)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_familia(default_limit_commond_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_laboral = get_words_ocrruence(words_laboral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('art', 508),\n",
       " ('luis', 379),\n",
       " ('vocal', 344),\n",
       " ('ley', 318),\n",
       " ('señor', 279),\n",
       " ('expediente', 274),\n",
       " ('doctor', 236),\n",
       " ('nro', 235),\n",
       " ('rubio', 228),\n",
       " ('n°', 219),\n",
       " ('blanc', 199),\n",
       " ('angulo', 198),\n",
       " ('mercedes', 191),\n",
       " ('sentencia', 185),\n",
       " ('nº', 178),\n",
       " ('enrique', 178),\n",
       " ('e', 178),\n",
       " ('m.', 177),\n",
       " ('recurso', 177),\n",
       " ('arabel', 176)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_laboral(default_limit_commond_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos-ayvd] *",
   "language": "python",
   "name": "conda-env-diplodatos-ayvd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
