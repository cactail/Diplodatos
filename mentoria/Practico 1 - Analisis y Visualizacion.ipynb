{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "### Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2021\n",
    "Búsqueda y Recomendación para Textos Legales\n",
    "\n",
    "Mentor: Jorge E. Pérez Villella\n",
    "\n",
    "# Práctico Análisis y Visualización\n",
    "\n",
    "Integrantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "* Generar un corpus con todos los documentos. \n",
    "\n",
    "* Dividir el corpus en tokens, graficar el histograma de frecuencia de palabras demostrando la ley Zipf. \n",
    "\n",
    "* Analizar palabras más frecuentes y menos frecuentes. Seleccionar 5 documentos de cada fuero y realizar el mismo análisis. ¿Se repiten las palabras? \n",
    "\n",
    "* Hacer lo mismo con n-gramas.\n",
    "\n",
    "* Visualizar la frecuencia de palabras en una nube de palabras.\n",
    "\n",
    "* Elaborar una breve conclusión de lo encontrado\n",
    "\n",
    "Fecha de Entrega: 6 de junio de 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar un corpus con todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c anaconda spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.examples import sentences\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos/MENORES\n",
      "Documentos/PENAL\n",
      "Documentos/FAMILIA\n",
      "Documentos/LABORAL\n"
     ]
    }
   ],
   "source": [
    "root_path = \"Documentos\"\n",
    "\n",
    "directories = [x[0] for x in os.walk(root_path)]\n",
    "\n",
    "directories.pop(0)\n",
    "\n",
    "for directory in directories:\n",
    "    print (directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_corpus_df(directories):\n",
    "      \n",
    "    corpus = []\n",
    "\n",
    "    for directory in directories:\n",
    "      \n",
    "        file_list = glob.glob(os.path.join(os.getcwd(), directory, \"*.txt\"))\n",
    "\n",
    "\n",
    "        for file_path in file_list:\n",
    "            with open(file_path) as f_input:\n",
    "                corpus.append([f_input.read() , directory])\n",
    "\n",
    "    return pd.DataFrame(corpus, columns=[\"text\", \"classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = generate_corpus_df(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unívoco:18900  Fecha: 04/04/2016\\n Materia Niñ...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/03/2013\\nJuzgado de la Niñez, Juventud y Vi...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los  autos  caratulados: ”A.,  A.  -  Denuncia...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Juzg. de Niñez, Adolescencia y Violencia Famil...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RIO CUARTO, 11/05/2018. Por evacuada la vista ...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUTO INTERLOCUTORIO NÚMERO: dieciséis (16)\\nCó...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Córdoba, 30 de mayo de 2018. Por recibido. Té...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba.\\nD...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          classifier\n",
       "0  DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...  Documentos/MENORES\n",
       "1  Unívoco:18900  Fecha: 04/04/2016\\n Materia Niñ...  Documentos/MENORES\n",
       "2  DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...  Documentos/MENORES\n",
       "3  13/03/2013\\nJuzgado de la Niñez, Juventud y Vi...  Documentos/MENORES\n",
       "4  Los  autos  caratulados: ”A.,  A.  -  Denuncia...  Documentos/MENORES\n",
       "5  Juzg. de Niñez, Adolescencia y Violencia Famil...  Documentos/MENORES\n",
       "6  RIO CUARTO, 11/05/2018. Por evacuada la vista ...  Documentos/MENORES\n",
       "7  AUTO INTERLOCUTORIO NÚMERO: dieciséis (16)\\nCó...  Documentos/MENORES\n",
       "8  “Córdoba, 30 de mayo de 2018. Por recibido. Té...  Documentos/MENORES\n",
       "9  DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba.\\nD...  Documentos/MENORES"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus_file(directory, corpus_file_name): \n",
    "    \n",
    "    outfilename = os.path.join(os.getcwd(), directory , corpus_file_name )\n",
    "    input_files = os.path.join(os.getcwd(), directory , '*.txt' )\n",
    "    \n",
    "    with open(outfilename, 'wb') as outfile:\n",
    "        for filename in glob.glob(input_files):\n",
    "            if filename == outfilename:\n",
    "                # don't want to copy the output into the output\n",
    "                continue\n",
    "            with open(filename, 'rb') as readfile:\n",
    "                shutil.copyfileobj(readfile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el corpus de cada fuero en el archivo corpust.txt. Hacemos esto puesto que es muchos menos \n",
    "# costoso que pasar a un unico string los valores del data frame\n",
    "\n",
    "corpus_file_name = \"corpus.txt\"\n",
    "for directory in directories:\n",
    "    generate_corpus_file(directory, corpus_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agregate_df_corpus(directories, corpus_file_name): \n",
    "    \n",
    "    agregate_df_corpus = pd.DataFrame()\n",
    "        \n",
    "    for directory in directories: \n",
    "        \n",
    "        corpus_file = os.path.join(os.getcwd(), directory , corpus_file_name ) \n",
    "        print(corpus_file)\n",
    "        with open(corpus_file, 'r') as file:\n",
    "            data = file.read().replace('\\n', ' ')\n",
    "            print(data[:10])\n",
    "            agregate_df_corpus.append({'text' : data, 'tag' : directory } , ignore_index = True)\n",
    "            print (\"Se agrego\")\n",
    "    \n",
    "    return agregate_df_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_agregate_df_corpus_2(directories, corpus_file_name): \n",
    "    \n",
    "    agregate_df_corpus = pd.DataFrame(columns=['text', 'tag'])\n",
    "        \n",
    "    for directory in directories: \n",
    "        \n",
    "        corpus_file = os.path.join(os.getcwd(), directory , corpus_file_name ) \n",
    "        data = open(corpus_file, 'r').read()\n",
    "        agregate_df_corpus = agregate_df_corpus.append({'text' : data, 'tag' : directory } , ignore_index = True)\n",
    "        \n",
    "    return agregate_df_corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregate_df_corpus = generate_agregate_df_corpus_2(directories ,corpus_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SALA PENAL - TRIBUNAL SUPERIOR\\n\\nProtocolo de...</td>\n",
       "      <td>Documentos/PENAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTO NÚMERO: sesenta y seis \\nCórdoba, cinco d...</td>\n",
       "      <td>Documentos/FAMILIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SALA LABORAL - TRIBUNAL SUPERIOR\\n\\nProtocolo ...</td>\n",
       "      <td>Documentos/LABORAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 tag\n",
       "0  DATOS DE LA CAUSA\\nSede: Ciudad de Córdoba. \\n...  Documentos/MENORES\n",
       "1  SALA PENAL - TRIBUNAL SUPERIOR\\n\\nProtocolo de...    Documentos/PENAL\n",
       "2  AUTO NÚMERO: sesenta y seis \\nCórdoba, cinco d...  Documentos/FAMILIA\n",
       "3  SALA LABORAL - TRIBUNAL SUPERIOR\\n\\nProtocolo ...  Documentos/LABORAL"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agregate_df_corpus[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir el corpus en tokens, graficar el histograma de frecuencia de palabras demostrando la ley Zipf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no funciona, consume mucha memoria\n",
    "def generate_corpus_by_tag(df, tag):\n",
    "    \n",
    "    corpus = corpus_df[corpus_df['classifier'] == classifier ].text.to_list()\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no funciona, consume mucha memoria\n",
    "spacy_nlp.max_length = 3000000\n",
    "for directory in directories:\n",
    "    print (f\"Generando corpus de {directory}\")\n",
    "    corpus = \"\".join(corpus_df[corpus_df['classifier'] == classifier ].text.to_list())\n",
    "    corpus_doc = spacy_nlp(corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp.max_length = 7000000\n",
    "doc = spacy_nlp(agregate_df_corpus[agregate_df_corpus['tag'] == 'Documentos/MENORES'].text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_freq = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 11660),\n",
       " ('y', 10122),\n",
       " ('a', 8780),\n",
       " ('\\n\\n', 2170),\n",
       " ('fs', 2010),\n",
       " ('niño', 1666),\n",
       " ('\\n', 1410),\n",
       " ('o', 1158),\n",
       " ('Sra.', 1156),\n",
       " ('art', 1106)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_penal = spacy_nlp(agregate_df_corpus[agregate_df_corpus['tag'] == 'Documentos/PENAL'].text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos-ayvd] *",
   "language": "python",
   "name": "conda-env-diplodatos-ayvd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
