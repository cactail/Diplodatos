{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "### Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2021\n",
    "Búsqueda y Recomendación para Textos Legales\n",
    "\n",
    "Mentor: Jorge E. Pérez Villella\n",
    "\n",
    "# Práctico Análisis y Visualización\n",
    "\n",
    "Integrantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "Normalizar el corpus generado en el práctico anterior, teniendo en cuenta los siguientes aspectos:\n",
    "\n",
    "* tokenización, \n",
    "* pasar a minúsculas, \n",
    "* separar puntuación, \n",
    "* stemming y lematización, \n",
    "* eliminar stopwords (o no), \n",
    "* eliminar las palabras con frecuencia menor a n. \n",
    "\n",
    "Analizar las palabras más frecuentes de todo el corpus, por fuero y de 5 documentos. Compararlo con el resultado obtenido en el ejercicio anterior. Se observa algún cambio significativo?\n",
    "\n",
    "Hacer una explicación con ejemplos tomando algunas palabras al azar entre lo que es stemming y lemmatizing para entender que nos da cada uno de estos procesos y cual es conveniente utilizar en cada caso.\n",
    "\n",
    "Opcional:\n",
    "\n",
    "* Investigar que es Segmentación y compararlo con Tokenización. Ejemplificar con un documento.\n",
    "* Investigar NER (Named Entity Recognition - Reconocimiento de Entitades Nombradas). Buscar las Entidadas Nombradas mas frecuentes en todo el corpus y por fuero. \n",
    "\n",
    "\n",
    "Fecha de Entrega: 4 de julio de 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c conda-forge spacy=3.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.0.6) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "/Users/coviedo/opt/anaconda3/envs/diplodatos-ayvd/lib/python3.6/site-packages/spacy\u001b[0m\n",
      "\n",
      "NAME              SPACY            VERSION                            \n",
      "es_core_news_md   >=3.0.0,<3.1.0   \u001b[38;5;2m3.0.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_sm    >=3.0.0,<3.1.0   \u001b[38;5;2m3.0.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import datetime\n",
    "from spacy.tokens.doc import Doc\n",
    "import pickle\n",
    "\n",
    "import lib.nlp_cba as nlp_cba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.6\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre con el cual se graba el data frame corpus de todas las sentencias. Cada sentencia es una fila\n",
    "corpus_file_name = \"corpus.csv\"\n",
    "\n",
    "#Nombre con el cual se graba el data frame que tiene el corpus sumarizado por fuero. Todo el texto de las sentencias de un\n",
    "# fuero esta en una sola fila\n",
    "agregated_corups_df_file_name = \"agregated_corpus.csv\"\n",
    "\n",
    "\n",
    "load_from_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El data frame corpus_df se carga desde el archivo corpus.csv\n"
     ]
    }
   ],
   "source": [
    "print (f\"El data frame corpus_df se carga desde el archivo {corpus_file_name}\")\n",
    "corpus_df = pd.read_csv(corpus_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El data frame agregated_corups_df se carga desde el archivo agregated_corpus.csv\n"
     ]
    }
   ],
   "source": [
    "print (f\"El data frame agregated_corups_df se carga desde el archivo {agregated_corups_df_file_name}\")\n",
    "agregated_corups_df = pd.read_csv(agregated_corups_df_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datos de la causa sede  ciudad de córdoba.  de...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unívoco 18900  fecha  04/04/2016  materia niñe...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13/03/2013 juzgado de la niñez  juventud y vio...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>los  autos  caratulados   a.   a.  -  denuncia...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juzg. de niñez  adolescencia y violencia famil...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          classifier\n",
       "0  datos de la causa sede  ciudad de córdoba.  de...  Documentos/MENORES\n",
       "1  unívoco 18900  fecha  04/04/2016  materia niñe...  Documentos/MENORES\n",
       "2  13/03/2013 juzgado de la niñez  juventud y vio...  Documentos/MENORES\n",
       "3  los  autos  caratulados   a.   a.  -  denuncia...  Documentos/MENORES\n",
       "4  juzg. de niñez  adolescencia y violencia famil...  Documentos/MENORES"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datos de la causa sede  ciudad de córdoba.  de...</td>\n",
       "      <td>Documentos/MENORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sala penal - tribunal superior  protocolo de s...</td>\n",
       "      <td>Documentos/PENAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto número  sesenta y seis  córdoba  cinco de...</td>\n",
       "      <td>Documentos/FAMILIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sala laboral - tribunal superior  protocolo de...</td>\n",
       "      <td>Documentos/LABORAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          classifier\n",
       "0  datos de la causa sede  ciudad de córdoba.  de...  Documentos/MENORES\n",
       "1  sala penal - tribunal superior  protocolo de s...    Documentos/PENAL\n",
       "2  auto número  sesenta y seis  córdoba  cinco de...  Documentos/FAMILIA\n",
       "3  sala laboral - tribunal superior  protocolo de...  Documentos/LABORAL"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agregated_corups_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomalización de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el lenguaje español en spacy\n",
    "spacy_nlp = spacy.load(\"es_core_news_md\") \n",
    "spacy_nlp.max_length = 5000000\n",
    "\n",
    "Doc.set_extension('text_id', default=False, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos las STOP_WORDS que viene definidas por defecto\n",
    "#spacy.lang.es.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop_words que no estan contempladas en Spacy y consideramos necesario sacarlas\n",
    "\n",
    "customs_stop_words = ['y' , 'e' , 'a']\n",
    "\n",
    "for custom_stop_word in customs_stop_words:\n",
    "   spacy_nlp.vocab[custom_stop_word].is_stop = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clases para filtrar y transformar datos en Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyTextNormalizer:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.filters = []\n",
    "        self.transformers = []\n",
    "        self.documents = []\n",
    "        \n",
    "    def addFilter(self, filter):\n",
    "        self.filters.append(filter)\n",
    "        \n",
    "    def addTransformer(self, transformer):\n",
    "        self.transformers.append(transformer)\n",
    "        \n",
    "    \n",
    "    def fit(self , spacy_tuples):\n",
    "        self.documents = []\n",
    "        for doc,context in spacy_tuples:\n",
    "            doc._.text_id = context[\"text_id\"]\n",
    "            \n",
    "            self.documents.append(doc)\n",
    "        \n",
    "        \n",
    "    def normalize(self, filters = [], transformers = []):\n",
    "        documents = []\n",
    "        for doc in self.documents:\n",
    "            words = []\n",
    "            \n",
    "            for word in doc:\n",
    "                include = True\n",
    "\n",
    "                for filter in filters:\n",
    "                    include = filter.execute(word)\n",
    "                    if not include: \n",
    "                        break\n",
    "        \n",
    "                if include:\n",
    "                    \n",
    "                    transformed_res = []\n",
    "                    transformed_res.append(word)\n",
    "                    \n",
    "                    for transformer in transformers:\n",
    "                        transformed_res.append(transformer.transform(word))\n",
    "                        \n",
    "                    words.append(transformed_res)       \n",
    "        \n",
    "            documents.append(( doc ,words))\n",
    "        \n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapMultipleCharsProcessor:\n",
    "\n",
    "    def process(self, text , replace_chars):\n",
    "        \n",
    "        for ch in replace_chars:\n",
    "            text = text.replace(ch[0],ch[1])\n",
    "\n",
    "        \n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola u este'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_replace = [('á' , 'a') , ('é' , 'e') , ('í', 'i') , ('ó' , 'o') , ('ú' , 'u')]\n",
    "mapMultipleCharsProcessor = MapMultipleCharsProcessor()\n",
    "mapMultipleCharsProcessor.process(\"Holá ú esté\" , chars_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RemoveStopWordsAndPuntctuationFilter:\n",
    "    \n",
    "    def execute(self, word):\n",
    "        return not word.is_stop and not word.is_punct\n",
    "\n",
    "\n",
    "class RemoveSpaceFilter:\n",
    "    def execute(self, word):\n",
    "        return not word.is_space\n",
    "    \n",
    "    \n",
    "class ToLowerCaseTransformer:\n",
    "    def transform(self, word):\n",
    "        return word.lower_\n",
    "    \n",
    "class ToLemaTransformer:\n",
    "    def transform(self, word):\n",
    "        return mapMultipleCharsProcessor.process(word.lemma_ , chars_replace)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtros y transformes que vamos a utilizar para normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtros y transformers\n",
    "\n",
    "removeSpaceFilter = RemoveSpaceFilter()\n",
    "removeStopWordsAndPuntctuationFilter = RemoveStopWordsAndPuntctuationFilter ()\n",
    "\n",
    "\n",
    "toLowerCaseTransformer = ToLowerCaseTransformer()\n",
    "toLemaTransformer = ToLemaTransformer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de filtros y transformers\n",
    "texto = [\n",
    "    (\"Pregunta?\", {\"text_id\": \"1\"} ),\n",
    "    (\"Pregunta.\", {\"text_id\": \"1\"} ),\n",
    "    (\"Estaba comiendo.\", {\"text_id\": \"1\"} ),\n",
    "    (\"Muchos espacios en     blanco .\", {\"text_id\": \"1\"} )\n",
    "    ]\n",
    "\n",
    "doc_tuples = spacy_nlp.pipe(texto , as_tuples=True , n_process=-1  )\n",
    "\n",
    "\n",
    "spacyTextNormalizer = SpacyTextNormalizer()\n",
    "\n",
    "spacyTextNormalizer.fit(doc_tuples)\n",
    "result = spacyTextNormalizer.normalize(transformers=[toLemaTransformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Pregunta?, [[Pregunta, 'Pregunta'], [?, '?']]),\n",
       " (Pregunta., [[Pregunta, 'Pregunta'], [., '.']]),\n",
       " (Estaba comiendo., [[Estaba, 'estar'], [comiendo, 'comer'], [., '.']]),\n",
       " (Muchos espacios en     blanco .,\n",
       "  [[Muchos, 'mucho'],\n",
       "   [espacios, 'espacio'],\n",
       "   [en, 'en'],\n",
       "   [    , '    '],\n",
       "   [blanco, 'blanco'],\n",
       "   [., '.']])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result[0][0]._.text_id\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremadamente lento este enfoque para el caso de procesar el copus por fuero. El length del string del texto del corpus es 'grande' y \n",
    "# hace que sea lento el procesamiento\n",
    "# Código deprecado\n",
    "\n",
    "if False:\n",
    "    texto = [(agregated_corups_df.iloc[2,].text , {\"text_id\": \"1\"})]\n",
    "\n",
    "    doc_tuples = spacy_nlp.pipe(texto , as_tuples=True ,batch_size=50, n_process=4 , disable=[\"tok2vec\", \"tagger\",  \"attribute_ruler\"] )\n",
    "\n",
    "    result = spacyTextNormalizer.normalize(doc_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armamos el array de tuplas a partir del data frame corpus_df. Usamos este data frame y no el agregated_corups_df puesto\n",
    "# que el array de texto por tupla es muy grande y Spacy requiere más memoria ademas de se notablemente lento\n",
    "\n",
    "if not load_from_pickle:\n",
    "\n",
    "    texto = corpus_df.apply( lambda x : (x['text'] , {\"text_id\": \"1\"}) , axis=1)\n",
    "    start_time = datetime.datetime.now()\n",
    "    doc_tuples = spacy_nlp.pipe(texto , as_tuples=True ,batch_size=50, n_process=4  )\n",
    "\n",
    "    spacyTextNormalizer.fit(doc_tuples)\n",
    "    stop_time = datetime.datetime.now()\n",
    "\n",
    "    print (f\"Tiempo de procesamiento: {stop_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poniendo a True serealizamos la instancia spacyTextNormalizer. Esto no permite reconstruir el objeto por medio del\n",
    "# archivo serealizado. Levantar el archivo y recrear el objeto es mucho más rápido de recostruir el objeto usando nlp.pipe y fit\n",
    "if False:\n",
    "    filehandler = open(\"normilizer.pkl\", 'wb') \n",
    "    pickle.dump(spacyTextNormalizer, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 0:00:10.055415\n"
     ]
    }
   ],
   "source": [
    "#Recreamos el objeto spacyTextNormalizer desde un archivo, ver la explicación del punto anterior\n",
    "if load_from_pickle:\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    filehandler = open(\"normilizer.pkl\", 'rb') \n",
    "    spacyTextNormalizer = pickle.load(filehandler)\n",
    "    stop_time = datetime.datetime.now()  \n",
    "    \n",
    "    print (f\"Tiempo de procesamiento: {stop_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos: 243\n",
      "Tiempo de procesamiento: 0:00:04.155772\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "filters = [removeSpaceFilter,removeStopWordsAndPuntctuationFilter]\n",
    "\n",
    "transformers = [toLemaTransformer]\n",
    "\n",
    "result = spacyTextNormalizer.normalize(filters=filters, transformers=transformers)\n",
    "\n",
    "stop_time = datetime.datetime.now()\n",
    "\n",
    "print (f\"Cantidad de documentos: {len(result)}\")\n",
    "print (f\"Tiempo de procesamiento: {stop_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[unívoco, 'univoco'],\n",
       " [18900, '18900'],\n",
       " [fecha, 'fecha'],\n",
       " [04/04/2016, '04/04/2016'],\n",
       " [materia, 'materia'],\n",
       " [niñez, 'niñez'],\n",
       " [revista, 'revista'],\n",
       " [familia, 'familia'],\n",
       " [niñez, 'niñez'],\n",
       " [número, 'numero'],\n",
       " [147, '147'],\n",
       " [tribunal, 'tribunal'],\n",
       " [juzgado, 'juzgado'],\n",
       " [niñez, 'niñez'],\n",
       " [adolescencia, 'adolescencia'],\n",
       " [y, 'y'],\n",
       " [violencia, 'violencia'],\n",
       " [familiar, 'familiar'],\n",
       " [4ta, '4ta'],\n",
       " [nom, 'nom'],\n",
       " [sec, 'sec'],\n",
       " [12, '12'],\n",
       " [cordoba, 'cordoba'],\n",
       " [resolución, 'resolucion'],\n",
       " [carátula, 'caratula'],\n",
       " [v., 'v.'],\n",
       " [a., 'a.'],\n",
       " [m., 'm.'],\n",
       " [control, 'control'],\n",
       " [legalidad, 'legalidad'],\n",
       " [titulo, 'titulo'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [solicitud, 'solicitud'],\n",
       " [cese, 'cese'],\n",
       " [rechazo, 'rechazo'],\n",
       " [plazos, 'plazo'],\n",
       " [art, 'art'],\n",
       " [607, '607'],\n",
       " [cccn, 'cccn'],\n",
       " [y, 'y'],\n",
       " [5to, '5to'],\n",
       " [párrafo, 'parrafo'],\n",
       " [art, 'art'],\n",
       " [48, '48'],\n",
       " [ley, 'ley'],\n",
       " [9944, '9944'],\n",
       " [inaplicabilidad, 'inaplicabilidad'],\n",
       " [principio, 'principio'],\n",
       " [favor, 'favor'],\n",
       " [minoris, 'minoris'],\n",
       " [interés, 'interes'],\n",
       " [superior, 'superior'],\n",
       " [capacidad, 'capacidad'],\n",
       " [derecho, 'derecho'],\n",
       " [a, 'a'],\n",
       " [oído, 'oer'],\n",
       " [falta, 'falta'],\n",
       " [consentimiento, 'consentimiento'],\n",
       " [adolescente, 'adolescente'],\n",
       " [a, 'a'],\n",
       " [adoptado, 'adoptar'],\n",
       " [descripción, 'descripcion'],\n",
       " [caso, 'caso'],\n",
       " [jueza, 'jueza'],\n",
       " [a, 'a'],\n",
       " [cargo, 'cargo'],\n",
       " [control, 'control'],\n",
       " [legalidad, 'legalidad'],\n",
       " [medida, 'medida'],\n",
       " [tercer, 'tercer'],\n",
       " [nivel, 'nivel'],\n",
       " [rechazó, 'rechazar'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [y, 'y'],\n",
       " [declaró, 'declarar'],\n",
       " [inaplicabilidad, 'inaplicabilidad'],\n",
       " [plazos, 'plazo'],\n",
       " [previstos, 'previsto'],\n",
       " [inc, 'inc'],\n",
       " [c, 'c'],\n",
       " [art, 'art'],\n",
       " [607, '607'],\n",
       " [cccn, 'cccn'],\n",
       " [y, 'y'],\n",
       " [5to, '5to'],\n",
       " [párrafo, 'parrafo'],\n",
       " [art, 'art'],\n",
       " [48, '48'],\n",
       " [ley, 'ley'],\n",
       " [9944, '9944'],\n",
       " [fundamentos, 'fundamento'],\n",
       " [iudex, 'iudex'],\n",
       " [ente, 'ente'],\n",
       " [administrativo, 'administrativo'],\n",
       " [agotó, 'agotar'],\n",
       " [instancias, 'instancia'],\n",
       " [previas, 'previo'],\n",
       " [y, 'y'],\n",
       " [necesarias, 'necesario'],\n",
       " [lograr, 'lograr'],\n",
       " [retorno, 'retorno'],\n",
       " [adolescente, 'adolescente'],\n",
       " [a, 'a'],\n",
       " [familia, 'familia'],\n",
       " [biológica, 'biologico'],\n",
       " [falta, 'falta'],\n",
       " [consentimiento, 'consentimiento'],\n",
       " [a, 'a'],\n",
       " [adoptado, 'adoptar'],\n",
       " [expresada, 'expresado'],\n",
       " [forma, 'forma'],\n",
       " [personal, 'personal'],\n",
       " [y, 'y'],\n",
       " [a, 'a'],\n",
       " [defensa, 'defensa'],\n",
       " [técnica, 'tecnico'],\n",
       " [presenta, 'presentar'],\n",
       " [obstáculo, 'obstaculo'],\n",
       " [a, 'a'],\n",
       " [declaración, 'declaracion'],\n",
       " [adoptabilidad, 'adoptabilidad'],\n",
       " [y, 'y'],\n",
       " [consecuente, 'consecuente'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [asimismo, 'asimismo'],\n",
       " [dispuso, 'disponer'],\n",
       " [atento, 'atento'],\n",
       " [padecer, 'padecer'],\n",
       " [joven, 'joven'],\n",
       " [institucionalizado-, 'institucionalizado-'],\n",
       " [diabetes, 'diabetes'],\n",
       " [mellitus, 'mellitus'],\n",
       " [senaf, 'senaf'],\n",
       " [deberá, 'deber'],\n",
       " [continuar, 'continuar'],\n",
       " [intervención, 'intervencion'],\n",
       " [a, 'a'],\n",
       " [garantizar, 'garantizar'],\n",
       " [derechos, 'derecho'],\n",
       " [fundamentales, 'fundamental'],\n",
       " [1, '1'],\n",
       " [caso, 'caso'],\n",
       " [marras, 'marra'],\n",
       " [situación, 'situacion'],\n",
       " [prevista, 'previsto'],\n",
       " [ley, 'ley'],\n",
       " [exige, 'exigir'],\n",
       " [mirada, 'mirada'],\n",
       " [sistémica, 'sistemico'],\n",
       " [normativa, 'normativa'],\n",
       " [provincial, 'provincial'],\n",
       " [y, 'y'],\n",
       " [nacional, 'nacional'],\n",
       " [comunión, 'comunion'],\n",
       " [tratados, 'tratado'],\n",
       " [internacionales, 'internacional'],\n",
       " [derechos, 'derechos'],\n",
       " [humanos, 'humanos'],\n",
       " [consecuente, 'consecuente'],\n",
       " [prevalencia, 'prevalencia'],\n",
       " [principio, 'principio'],\n",
       " [favor, 'favor'],\n",
       " [minoris, 'minoris'],\n",
       " [y, 'y'],\n",
       " [interés, 'interes'],\n",
       " [superior, 'superior'],\n",
       " [niño, 'niño'],\n",
       " [2, '2'],\n",
       " [persona, 'persona'],\n",
       " [menor, 'menor'],\n",
       " [edad, 'edad'],\n",
       " [derecho, 'derecho'],\n",
       " [a, 'a'],\n",
       " [oída, 'oida'],\n",
       " [proceso, 'proceso'],\n",
       " [judicial, 'judicial'],\n",
       " [concierne, 'concernir'],\n",
       " [a, 'a'],\n",
       " [participar, 'participar'],\n",
       " [decisiones, 'decision'],\n",
       " [persona, 'persona'],\n",
       " [art, 'art'],\n",
       " [26, '26'],\n",
       " [3er, '3er'],\n",
       " [párrafo, 'parrafo'],\n",
       " [cccn, 'cccn'],\n",
       " [consonancia, 'consonancia'],\n",
       " [art, 'art'],\n",
       " [12, '12'],\n",
       " [cidn, 'cidn'],\n",
       " [y, 'y'],\n",
       " [observación, 'observacion'],\n",
       " [nro, 'nro'],\n",
       " [doce, 'doce'],\n",
       " [comité, 'comite'],\n",
       " [derechos, 'derecho'],\n",
       " [niño, 'niño'],\n",
       " [3, '3'],\n",
       " [régimen, 'regimen'],\n",
       " [capacidad, 'capacidad'],\n",
       " [menores, 'menor'],\n",
       " [edad, 'edad'],\n",
       " [asienta, 'asentar'],\n",
       " [condiciones, 'condicion'],\n",
       " [etarias, 'etaria'],\n",
       " [puras, 'puro'],\n",
       " [introduce, 'introducir'],\n",
       " [pauta, 'pauta'],\n",
       " [maleable, 'maleable'],\n",
       " [y, 'y'],\n",
       " [permeable, 'permeable'],\n",
       " [madurez, 'madurez'],\n",
       " [suficiente, 'suficiente'],\n",
       " [permite, 'permitir'],\n",
       " [discernir, 'discernir'],\n",
       " [caso, 'caso'],\n",
       " [concreto, 'concreto'],\n",
       " [posibilidad, 'posibilidad'],\n",
       " [tomar, 'tomar'],\n",
       " [decisión, 'decision'],\n",
       " [razonada, 'razonado'],\n",
       " [relación, 'relacion'],\n",
       " [acto, 'acto'],\n",
       " [concreto, 'concreto'],\n",
       " [apareciendo, 'aparecer'],\n",
       " [sistema, 'sistema'],\n",
       " [justo, 'justo'],\n",
       " [y, 'y'],\n",
       " [cercano, 'cercano'],\n",
       " [respeto, 'respeto'],\n",
       " [persona, 'persona'],\n",
       " [humana, 'humano'],\n",
       " [cccn, 'cccn'],\n",
       " [comentado, 'comentado'],\n",
       " [marisa, 'marisa'],\n",
       " [herrera, 'herrero'],\n",
       " [gustavo, 'gustavo'],\n",
       " [caramelo, 'caramelo'],\n",
       " [y, 'y'],\n",
       " [sebastián, 'sebastian'],\n",
       " [picasso, 'picasso'],\n",
       " [4, '4'],\n",
       " [falta, 'falta'],\n",
       " [consentimiento, 'consentimiento'],\n",
       " [adolescente, 'adolescente'],\n",
       " [a, 'a'],\n",
       " [adoptado, 'adoptar'],\n",
       " [erige, 'erigir'],\n",
       " [valladar, 'valladar'],\n",
       " [infranqueable, 'infranqueable'],\n",
       " [a, 'a'],\n",
       " [declaración, 'declaracion'],\n",
       " [adoptabilidad, 'adoptabilidad'],\n",
       " [art, 'art'],\n",
       " [595, '595'],\n",
       " [inc, 'inc'],\n",
       " [f, 'f'],\n",
       " [cccn, 'cccn'],\n",
       " [y, 'y'],\n",
       " [a, 'a'],\n",
       " [imposibilidad, 'imposibilidad'],\n",
       " [proceder, 'proceder'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [anuencia, 'anuencia'],\n",
       " [joven, 'joven'],\n",
       " [declaración, 'declaracion'],\n",
       " [adoptabilidad, 'adoptabilidad'],\n",
       " [devendría, 'devenir'],\n",
       " [saco, 'saco'],\n",
       " [roto, 'roto'],\n",
       " [posterior, 'posterior'],\n",
       " [juicio, 'juicio'],\n",
       " [adopción, 'adopcion'],\n",
       " [virtud, 'virtud'],\n",
       " [requisito, 'requisito'],\n",
       " [procedencia, 'procedencia'],\n",
       " [aquiescencia, 'aquiescencia'],\n",
       " [niño, 'niño'],\n",
       " [a, 'a'],\n",
       " [tales, 'tal'],\n",
       " [fines, 'fin'],\n",
       " [conformidad, 'conformidad'],\n",
       " [prestada, 'prestado'],\n",
       " [menor, 'menor'],\n",
       " [aspecto, 'aspecto'],\n",
       " [central, 'central'],\n",
       " [a, 'a'],\n",
       " [regla, 'regla'],\n",
       " [autonomía, 'autonomia'],\n",
       " [progresiva, 'progresivo'],\n",
       " [capacidad, 'capacidad'],\n",
       " [civil, 'civil'],\n",
       " [art, 'art'],\n",
       " [639, '639'],\n",
       " [cccn, 'cccn'],\n",
       " [5, '5'],\n",
       " [bidart, 'bidart'],\n",
       " [campos, 'campo'],\n",
       " [sostiene, 'sostener'],\n",
       " [cumplir, 'cumplir'],\n",
       " [estricta, 'estricto'],\n",
       " [función, 'funcion'],\n",
       " [impartir, 'impartir'],\n",
       " [justicia, 'justicia'],\n",
       " [deber, 'deber'],\n",
       " [constitucional, 'constitucional'],\n",
       " [afianzar, 'afianzar'],\n",
       " [justicia, 'justicia'],\n",
       " [juez, 'juez'],\n",
       " [y, 'y'],\n",
       " [juzgar, 'juzgar'],\n",
       " [ley, 'ley'],\n",
       " [aplicación, 'aplicacion'],\n",
       " [justa, 'justo'],\n",
       " [o, 'o'],\n",
       " [injusta, 'injusto'],\n",
       " [y, 'y'],\n",
       " [a, 'a'],\n",
       " [tenor, 'tenor'],\n",
       " [circunstancias, 'circunstancia'],\n",
       " [caso, 'caso'],\n",
       " [convence, 'convencer'],\n",
       " [objetivamente, 'objetivamente'],\n",
       " [aplicarla, 'aplicar el'],\n",
       " [conduce, 'conducir'],\n",
       " [a, 'a'],\n",
       " [dictar, 'dictar'],\n",
       " [sentencia, 'sentencia'],\n",
       " [injusta, 'injusto'],\n",
       " [abstenerse, 'abstener el'],\n",
       " [aplicarla, 'aplicar el'],\n",
       " [ley, 'ley'],\n",
       " [halla, 'hallar'],\n",
       " [constitución, 'constitucion'],\n",
       " [y, 'y'],\n",
       " [tratados, 'tratado'],\n",
       " [internacionales, 'internacional'],\n",
       " [6, '6'],\n",
       " [profesionales, 'profesional'],\n",
       " [salud, 'salud'],\n",
       " [voluntad, 'voluntad'],\n",
       " [niños, 'niño'],\n",
       " [y, 'y'],\n",
       " [adolescentes, 'adolescente'],\n",
       " [terapias, 'terapia'],\n",
       " [o, 'o'],\n",
       " [procedimientos, 'procedimiento'],\n",
       " [competencia, 'competencia'],\n",
       " [y, 'y'],\n",
       " [discernimiento, 'discernimiento'],\n",
       " [art, 'art'],\n",
       " [2, '2'],\n",
       " [°, '°'],\n",
       " [inc, 'inc'],\n",
       " [e, 'e'],\n",
       " [decreto, 'decreto'],\n",
       " [1089/2012, '1089/2012'],\n",
       " [juzg, 'juzg'],\n",
       " [niñez, 'niñez'],\n",
       " [adolescencia, 'adolescencia'],\n",
       " [y, 'y'],\n",
       " [violencia, 'violencia'],\n",
       " [familiar, 'familiar'],\n",
       " [4ta, '4ta'],\n",
       " [nom, 'nom'],\n",
       " [cba, 'cba'],\n",
       " [sec, 'sec'],\n",
       " [12, '12'],\n",
       " [04/04/2016, '04/04/2016'],\n",
       " [v., 'v.'],\n",
       " [a., 'a.'],\n",
       " [m., 'm.'],\n",
       " [control, 'control'],\n",
       " [legalidad, 'legalidad'],\n",
       " [fallo, 'fallo'],\n",
       " [reseñado, 'reseñado'],\n",
       " [maría, 'macer'],\n",
       " [elisa, 'elisa'],\n",
       " [depetris, 'depetri'],\n",
       " [y, 'y'],\n",
       " [vistos, 'visto'],\n",
       " [autos, 'auto'],\n",
       " [caratulados, 'caratulado'],\n",
       " [v., 'v.'],\n",
       " [a., 'a.'],\n",
       " [m., 'm.'],\n",
       " [control, 'control'],\n",
       " [legalidad, 'legalidad'],\n",
       " [expte, 'expte'],\n",
       " [n°, 'n°'],\n",
       " [2163435, '2163435'],\n",
       " [traídos, 'traido'],\n",
       " [a, 'a'],\n",
       " [despacho, 'despacho'],\n",
       " [a, 'a'],\n",
       " [fines, 'fin'],\n",
       " [resolver, 'resolver'],\n",
       " [legalidad, 'legalidad'],\n",
       " [solicitud, 'solicitud'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [protección, 'proteccion'],\n",
       " [derechos, 'derecho'],\n",
       " [adoptada, 'adoptado'],\n",
       " [relación, 'relacion'],\n",
       " [adolescente, 'adolescente'],\n",
       " [a., 'a.'],\n",
       " [m., 'm.'],\n",
       " [v., 'v.'],\n",
       " [d.n.i, 'd.n.i'],\n",
       " [n°, 'n°'],\n",
       " [nacido, 'nacer'],\n",
       " [hijo, 'hijo'],\n",
       " [p., 'p.'],\n",
       " [s., 's.'],\n",
       " [v., 'v.'],\n",
       " [d.n.i, 'd.n.i'],\n",
       " [n°, 'n°'],\n",
       " [y, 'y'],\n",
       " [a., 'a.'],\n",
       " [w., 'w.'],\n",
       " [f., 'f.'],\n",
       " [dni, 'dni'],\n",
       " [-según, '-segun'],\n",
       " [partida, 'partida'],\n",
       " [nacimiento, 'nacimiento'],\n",
       " [obrante, 'obrante'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [337, '337'],\n",
       " [conforme, 'conforme'],\n",
       " [atribuciones, 'atribucion'],\n",
       " [conferidas, 'conferida'],\n",
       " [art, 'art'],\n",
       " [48, '48'],\n",
       " [ley, 'ley'],\n",
       " [pcial, 'pcial'],\n",
       " [n°, 'n°'],\n",
       " [9944, '9944'],\n",
       " [resulta, 'resultar'],\n",
       " [1, '1'],\n",
       " [auto, 'auto'],\n",
       " [interlocutorio, 'interlocutorio'],\n",
       " [nº, 'nº'],\n",
       " [15, '15'],\n",
       " [fecha, 'fecha'],\n",
       " [agosto, 'agosto'],\n",
       " [año, 'año'],\n",
       " [mil, 'mil'],\n",
       " [quince, 'quince'],\n",
       " [fs, 'fs'],\n",
       " [190/196, '190/196'],\n",
       " [tribunal, 'tribunal'],\n",
       " [resolvió, 'resolver'],\n",
       " [ratificar, 'ratificar'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [dispuesta, 'dispuesto'],\n",
       " [senaf, 'senaf'],\n",
       " [fecha, 'fecha'],\n",
       " [diecisiete, 'diecisiete'],\n",
       " [diciembre, 'diciembre'],\n",
       " [año, 'año'],\n",
       " [mil, 'mil'],\n",
       " [catorce, 'catorce'],\n",
       " [asimismo, 'asimismo'],\n",
       " [dispuso, 'disponer'],\n",
       " [ratificar, 'ratificar'],\n",
       " [innovación, 'innovacion'],\n",
       " [medida, 'medida'],\n",
       " [permaneciendo, 'permanecer'],\n",
       " [niño, 'niño'],\n",
       " [casa, 'casa'],\n",
       " [progenitor, 'progenitor'],\n",
       " [sr, 'sr'],\n",
       " [w., 'w.'],\n",
       " [f., 'f.'],\n",
       " [a., 'a.'],\n",
       " [y, 'y'],\n",
       " [ratificar, 'ratificar'],\n",
       " [prórroga, 'prorroga'],\n",
       " [dicha, 'dicho'],\n",
       " [resolución, 'resolucion'],\n",
       " [y, 'y'],\n",
       " [efectos, 'efecto'],\n",
       " [cumplimentar, 'cumplimentar'],\n",
       " [garantías, 'garantia'],\n",
       " [procedimiento, 'procedimiento'],\n",
       " [previstas, 'previsto'],\n",
       " [legislación, 'legislacion'],\n",
       " [provincial, 'provincial'],\n",
       " [nacional, 'nacional'],\n",
       " [e, 'e'],\n",
       " [internacional, 'internacional'],\n",
       " [arts, 'arts'],\n",
       " [9, '9'],\n",
       " [apartado, 'apartado'],\n",
       " [2, '2'],\n",
       " [y, 'y'],\n",
       " [12, '12'],\n",
       " [apartado, 'apartado'],\n",
       " [2, '2'],\n",
       " [convención, 'convencion'],\n",
       " [derechos, 'derecho'],\n",
       " [niño, 'niño'],\n",
       " [ratificada, 'ratificado'],\n",
       " [ley, 'ley'],\n",
       " [nª, 'nª'],\n",
       " [23849, '23849'],\n",
       " [art, 'art'],\n",
       " [27, '27'],\n",
       " [inc, 'inc'],\n",
       " [c, 'c'],\n",
       " [ley, 'ley'],\n",
       " [26.061, '26.061'],\n",
       " [y, 'y'],\n",
       " [decreto, 'decreto'],\n",
       " [reglamentario, 'reglamentario'],\n",
       " [415/200, '415/200'],\n",
       " [prescripto, 'prescripto'],\n",
       " [ats, 'ats'],\n",
       " [3, '3'],\n",
       " [24, '24'],\n",
       " [y, 'y'],\n",
       " [27, '27'],\n",
       " [ley, 'ley'],\n",
       " [nacional, 'nacional'],\n",
       " [26061, '26061'],\n",
       " [y, 'y'],\n",
       " [arts, 'arts'],\n",
       " [31, '31'],\n",
       " [inc, 'inc'],\n",
       " [c, 'c'],\n",
       " [67, '67'],\n",
       " [inc, 'inc'],\n",
       " [b, 'b'],\n",
       " [74, '74'],\n",
       " [y, 'y'],\n",
       " [77, '77'],\n",
       " [ley, 'ley'],\n",
       " [9944, '9944'],\n",
       " [designa, 'designar'],\n",
       " [abogado, 'abogado'],\n",
       " [niño, 'niño'],\n",
       " [adolescente, 'adolescente'],\n",
       " [cuya, 'cuyo'],\n",
       " [situación, 'situacion'],\n",
       " [ocupa, 'ocupar'],\n",
       " [aceptando, 'aceptar'],\n",
       " [cargo, 'cargo'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [199, '199'],\n",
       " [2, '2'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [211, '211'],\n",
       " [glosa, 'glos'],\n",
       " [informe, 'informe'],\n",
       " [remitido, 'remitido'],\n",
       " [daniela, 'daniela'],\n",
       " [blasco, 'blasco'],\n",
       " [casa, 'casa'],\n",
       " [niño, 'niño'],\n",
       " [asociación, 'asociacion'],\n",
       " [civil, 'civil'],\n",
       " [3, '3'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [214/126, '214/126'],\n",
       " [y, 'y'],\n",
       " [a, 'a'],\n",
       " [mes, 'mes'],\n",
       " [septiembre, 'septiembre'],\n",
       " [año, 'año'],\n",
       " [mil, 'mil'],\n",
       " [quince, 'quince'],\n",
       " [recepta, 'receptar'],\n",
       " [audiencia, 'audiencia'],\n",
       " [a, 'a'],\n",
       " [comparecen, 'comparecer'],\n",
       " [a., 'a.'],\n",
       " [m., 'm.'],\n",
       " [v., 'v.'],\n",
       " [acompañado, 'acompañado'],\n",
       " [auxiliar, 'auxiliar'],\n",
       " [colaboradora, 'colaboradora'],\n",
       " [defensa, 'defensa'],\n",
       " [pública, 'publico'],\n",
       " [asesoría, 'asesoria'],\n",
       " [octavo, 'octavo'],\n",
       " [turno, 'turno'],\n",
       " [dra, 'dra'],\n",
       " [natalia, 'natalia'],\n",
       " [orta, 'ortar'],\n",
       " [córdoba, 'cordoba'],\n",
       " [carácter, 'caracter'],\n",
       " [abogada, 'abogada'],\n",
       " [niño-, 'niño-'],\n",
       " [representante, 'representante'],\n",
       " [casa, 'casa'],\n",
       " [niño, 'niño'],\n",
       " [daniel, 'daniel'],\n",
       " [malamut, 'malamut'],\n",
       " [lics, 'lics'],\n",
       " [daniela, 'daniela'],\n",
       " [blasco, 'blasco'],\n",
       " [y, 'y'],\n",
       " [clarisa, 'claris'],\n",
       " [sufia, 'sufia'],\n",
       " [dependientes, 'dependient'],\n",
       " [senaf, 'senaf'],\n",
       " [y, 'y'],\n",
       " [representante, 'representante'],\n",
       " [complementaria, 'complementario'],\n",
       " [4, '4'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [217, '217'],\n",
       " [y, 'y'],\n",
       " [a, 'a'],\n",
       " [mes, 'mes'],\n",
       " [septiembre, 'septiembre'],\n",
       " [recepta, 'receptar'],\n",
       " [audiencia, 'audiencia'],\n",
       " [designada, 'designado'],\n",
       " [autos, 'auto'],\n",
       " [a, 'a'],\n",
       " [comparecen, 'comparecer'],\n",
       " [sr, 'sr'],\n",
       " [w., 'w.'],\n",
       " [a., 'a.'],\n",
       " [y, 'y'],\n",
       " [representante, 'representante'],\n",
       " [complementaria, 'complementario'],\n",
       " [5, '5'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [256/260, '256/260'],\n",
       " [incorpora, 'incorporar'],\n",
       " [informe, 'informe'],\n",
       " [senaf, 'senaf'],\n",
       " [fecha, 'fecha'],\n",
       " [23, '23'],\n",
       " [septiembre, 'septiembre'],\n",
       " [año, 'año'],\n",
       " [2015, '2015'],\n",
       " [recibido, 'recibir'],\n",
       " [tribunal, 'tribunal'],\n",
       " [diez, 'diez'],\n",
       " [diciembre, 'diciembre'],\n",
       " [año, 'año'],\n",
       " [solicita, 'solicitar'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [relación, 'relacion'],\n",
       " [a, 'a'],\n",
       " [a., 'a.'],\n",
       " [6, '6'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [272, '272'],\n",
       " [obra, 'obra'],\n",
       " [certificado, 'certificado'],\n",
       " [surge, 'surgir'],\n",
       " [comunicación, 'comunicacion'],\n",
       " [telefónica, 'telefonico'],\n",
       " [cursada, 'cursado'],\n",
       " [profesionales, 'profesional'],\n",
       " [programa, 'programa'],\n",
       " [diabetes, 'diabetes'],\n",
       " [hospital, 'hospital'],\n",
       " [niños, 'niño'],\n",
       " [7, '7'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [170, '170'],\n",
       " [corre, 'correr'],\n",
       " [informe, 'informe'],\n",
       " [educativo, 'educativo'],\n",
       " [ipem, 'ipem'],\n",
       " [138, '138'],\n",
       " [8), '8)'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [276, '276'],\n",
       " [y, 'y'],\n",
       " [286/299, '286/299'],\n",
       " [agregan, 'agregar'],\n",
       " [informes, 'informe'],\n",
       " [dirección, 'direccion'],\n",
       " [asuntos, 'asunto'],\n",
       " [legales, 'legal'],\n",
       " [senaf, 'senaf'],\n",
       " [y, 'y'],\n",
       " [articulación, 'articulacion'],\n",
       " [y, 'y'],\n",
       " [gestión, 'gestion'],\n",
       " [territorial, 'territorial'],\n",
       " [comunican, 'comunicar'],\n",
       " [innovación, 'innovacion'],\n",
       " [medida, 'medida'],\n",
       " [niño, 'niño'],\n",
       " [a.m.v, 'a.m.v'],\n",
       " [reitera, 'reiterar'],\n",
       " [solicitud, 'solicitud'],\n",
       " [cese, 'cese'],\n",
       " [dicha, 'dicho'],\n",
       " [medida, 'medida'],\n",
       " [fuere, 'fuerar'],\n",
       " [trasladado, 'trasladar'],\n",
       " [a, 'a'],\n",
       " [aldeas, 'aldea'],\n",
       " [infantiles, 'infantil'],\n",
       " [9, '9'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [284, '284'],\n",
       " [y, 'y'],\n",
       " [312/315, '312/315'],\n",
       " [evacua, 'evacua'],\n",
       " [vista, 'visto'],\n",
       " [abogado, 'abogado'],\n",
       " [niño, 'niño'],\n",
       " [sr, 'sr'],\n",
       " [asesor, 'asesor'],\n",
       " [niñez, 'niñez'],\n",
       " [y, 'y'],\n",
       " [juventud, 'juventud'],\n",
       " [octavo, 'octavo'],\n",
       " [turno, 'turno'],\n",
       " [dr, 'dr'],\n",
       " [hugo, 'huir'],\n",
       " [contero, 'contero'],\n",
       " [10, '10'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [314/316, '314/316'],\n",
       " [evacúa, 'evacuar'],\n",
       " [vista, 'visto'],\n",
       " [sra, 'sra'],\n",
       " [asesora, 'asesora'],\n",
       " [niñez, 'niñez'],\n",
       " [y, 'y'],\n",
       " [juventud, 'juventud'],\n",
       " [séptimo, 'septimo'],\n",
       " [turno, 'turno'],\n",
       " [dra, 'dra'],\n",
       " [maría, 'macer'],\n",
       " [raquel, 'raquel'],\n",
       " [martínez, 'martinez'],\n",
       " [carácter, 'caracter'],\n",
       " [representante, 'representante'],\n",
       " [complementaria, 'complementario'],\n",
       " [11, '11'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [326/327, '326/327'],\n",
       " [incorpora, 'incorporar'],\n",
       " [informe, 'informe'],\n",
       " [remitido, 'remitido'],\n",
       " [programa, 'programa'],\n",
       " [diabetes, 'diabetes'],\n",
       " [hospital, 'hospital'],\n",
       " [niños, 'niño'],\n",
       " [ciudad, 'ciudad'],\n",
       " [córdoba, 'cordoba'],\n",
       " [12, '12'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [333/334, '333/334'],\n",
       " [glosa, 'glos'],\n",
       " [informe, 'informe'],\n",
       " [remitido, 'remitido'],\n",
       " [equipo, 'equipo'],\n",
       " [técnico, 'tecnico'],\n",
       " [fuero, 'fuero'],\n",
       " [13, '13'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [337, '337'],\n",
       " [incorpora, 'incorporar'],\n",
       " [copia, 'copia'],\n",
       " [partida, 'partida'],\n",
       " [nacimiento, 'nacimiento'],\n",
       " [adolescente, 'adolescente'],\n",
       " [autos, 'auto'],\n",
       " [desprende, 'desprender'],\n",
       " [reconocimiento, 'reconocimiento'],\n",
       " [paterno, 'paterno'],\n",
       " [efectuado, 'efectuado'],\n",
       " [sr, 'sr'],\n",
       " [w.f.a, 'w.f.a'],\n",
       " [14, '14'],\n",
       " [a, 'a'],\n",
       " [fs, 'fs'],\n",
       " [358, '358'],\n",
       " [glosa, 'glos'],\n",
       " [manifestaciones, 'manifestacion'],\n",
       " [formuladas, 'formulado'],\n",
       " [a.m.v, 'a.m.v'],\n",
       " [abogado, 'abogado'],\n",
       " [niño, 'niño'],\n",
       " [situación, 'situacion'],\n",
       " [actual, 'actual'],\n",
       " [residencia, 'residencia'],\n",
       " [aldeas, 'aldea'],\n",
       " [infantiles, 'infantil'],\n",
       " [15, '15'],\n",
       " [dictado, 'dictar'],\n",
       " [decreto, 'decreto'],\n",
       " [autos, 'auto'],\n",
       " [queda, 'quedar'],\n",
       " [causa, 'causa'],\n",
       " [resuelta, 'resolver'],\n",
       " [fs, 'fs'],\n",
       " [327, '327'],\n",
       " [vta, 'vta'],\n",
       " [y, 'y'],\n",
       " [considerando, 'considerar'],\n",
       " [i, 'i'],\n",
       " [tribunal, 'tribunal'],\n",
       " [llamado, 'llamar'],\n",
       " [a, 'a'],\n",
       " [expedirse, 'expedir el'],\n",
       " [marco, 'marco'],\n",
       " [control, 'control'],\n",
       " [legalidad, 'legalidad'],\n",
       " [relación, 'relacion'],\n",
       " [a, 'a'],\n",
       " [solicitud, 'solicitud'],\n",
       " [cese, 'cese'],\n",
       " [medida, 'medida'],\n",
       " [excepcional, 'excepcional'],\n",
       " [protección, 'proteccion'],\n",
       " [derechos, 'derecho'],\n",
       " [adoptada, 'adoptado'],\n",
       " [autoridad, 'autoridad'],\n",
       " [administrativa, 'administrativo'],\n",
       " [relación, 'relacion'],\n",
       " [niño, 'niño'],\n",
       " [a.m.v, 'a.m.v'],\n",
       " [a, 'a'],\n",
       " [procedencia, 'procedencia'],\n",
       " [ratificación, 'ratificacion'],\n",
       " [o, 'o'],\n",
       " [rechazo, 'rechazo'],\n",
       " [resultando, 'resultar'],\n",
       " [competente, 'competente'],\n",
       " [virtud, 'virtud'],\n",
       " [normado, 'normado'],\n",
       " [arts, 'art'],\n",
       " [39, '39'],\n",
       " [y, 'y'],\n",
       " [40, '40'],\n",
       " [ley, 'ley'],\n",
       " [nacional, 'nacional'],\n",
       " [nº, 'nº'],\n",
       " [26.061, '26.061'],\n",
       " [y, 'y'],\n",
       " [arts, 'arts'],\n",
       " [55, '55'],\n",
       " [56, '56'],\n",
       " [57, '57'],\n",
       " [y, 'y'],\n",
       " [67, '67'],\n",
       " [inc, 'inc'],\n",
       " [a, 'a'],\n",
       " [ley, 'ley'],\n",
       " [provincial, 'provincial'],\n",
       " [nº, 'nº'],\n",
       " [9944, '9944'],\n",
       " [ii, 'ii'],\n",
       " [previo, 'previo'],\n",
       " [adentrarnos, 'adentrar yo'],\n",
       " [análisis, 'analisis'],\n",
       " [cuestión, 'cuestion'],\n",
       " [sometida, 'sometido'],\n",
       " [a, 'a'],\n",
       " [estudio, 'estudio'],\n",
       " [y, 'y'],\n",
       " [pos, 'pos'],\n",
       " [enmarcar, 'enmarcar'],\n",
       " [jurídicamente, 'juridicamente'],\n",
       " [situación, 'situacion'],\n",
       " [fáctica, 'factico'],\n",
       " [planteada, 'planteado'],\n",
       " [especie, 'especie'],\n",
       " [resulta, 'resultar'],\n",
       " [insoslayable, 'insoslayable'],\n",
       " [efectuar, 'efectuar'],\n",
       " [precisiones, 'precision'],\n",
       " [liminares, 'liminar'],\n",
       " [permitirán, 'permitir'],\n",
       " [arribar, 'arribar'],\n",
       " [a, 'a'],\n",
       " [posición, 'posicion'],\n",
       " [ajustada, 'ajustado'],\n",
       " [a, 'a'],\n",
       " [lineamientos, 'lineamiento'],\n",
       " [fijados, 'fijado'],\n",
       " [código, 'codigo'],\n",
       " [civil, 'civil'],\n",
       " [y, 'y'],\n",
       " [comercial, 'comercial'],\n",
       " [nación, 'nacion'],\n",
       " [y, 'y'],\n",
       " [tratados, 'tratado'],\n",
       " [internaciones, 'internacion'],\n",
       " [veamos, 'ver'],\n",
       " [a, 'a'],\n",
       " [participación, 'participacion'],\n",
       " [activa, 'activo'],\n",
       " [adolescente, 'adolescente'],\n",
       " [a.m.v, 'a.m.v'],\n",
       " [cumplimiento, 'cumplimiento'],\n",
       " [proceso, 'proceso'],\n",
       " [garantías, 'garantia'],\n",
       " [procesales, 'procesal'],\n",
       " [ccyc, 'ccyc'],\n",
       " [dispone, 'disponer'],\n",
       " [art, 'art'],\n",
       " [26, '26'],\n",
       " [3er, '3er'],\n",
       " [párrafo, 'parrafo'],\n",
       " [persona, 'persona'],\n",
       " [menor, 'menor'],\n",
       " [edad, 'edad'],\n",
       " [derecho, 'derecho'],\n",
       " [a, 'a'],\n",
       " [oída, 'oida'],\n",
       " [proceso, 'proceso'],\n",
       " [judicial, 'judicial'],\n",
       " [concierne, 'concernir'],\n",
       " [a, 'a'],\n",
       " [participar, 'participar'],\n",
       " [decisiones, 'decision'],\n",
       " [persona, 'persona'],\n",
       " [disposición, 'disposicion'],\n",
       " [consonancia, 'consonancia'],\n",
       " [art, 'art'],\n",
       " [12, '12'],\n",
       " [convención, 'convencion'],\n",
       " [derechos, 'derecho'],\n",
       " [niño, 'niño'],\n",
       " [y, 'y'],\n",
       " [observación, 'observacion'],\n",
       " [nro, 'nro'],\n",
       " [doce, 'doce'],\n",
       " [comité, 'comite'],\n",
       " [derechos, 'derecho'],\n",
       " [niño, 'niño'],\n",
       " [línea, 'linea'],\n",
       " [reconocida, 'reconocido'],\n",
       " [doctrina, 'doctrina'],\n",
       " [sostiene, 'sostener'],\n",
       " [régimen, 'regimen'],\n",
       " [capacidad, 'capacidad'],\n",
       " [menores, 'menor'],\n",
       " [edad, 'edad'],\n",
       " [asienta, 'asentar'],\n",
       " [condiciones, 'condicion'],\n",
       " [etarias, 'etaria'],\n",
       " [puras, 'puro'],\n",
       " [introduce, 'introducir'],\n",
       " [pauta, 'pauta'],\n",
       " [maleable, 'maleable'],\n",
       " [y, 'y'],\n",
       " [permeable, 'permeable'],\n",
       " [madurez, 'madurez'],\n",
       " [suficiente, 'suficiente'],\n",
       " [permite, 'permitir'],\n",
       " [discernir, 'discernir'],\n",
       " [caso, 'caso'],\n",
       " [concreto, 'concreto'],\n",
       " [posibilidad, 'posibilidad'],\n",
       " [tomar, 'tomar'],\n",
       " [decisión, 'decision'],\n",
       " [razonada, 'razonado'],\n",
       " [relación, 'relacion'],\n",
       " [acto, 'acto'],\n",
       " [concreto, 'concreto'],\n",
       " [apareciendo, 'aparecer'],\n",
       " [sistema, 'sistema'],\n",
       " [justo, 'justo'],\n",
       " [y, 'y'],\n",
       " [cercano, 'cercano'],\n",
       " [respeto, 'respeto'],\n",
       " [persona, 'persona'],\n",
       " [humana, 'humano'],\n",
       " [código, 'codigo'],\n",
       " [civil, 'civil'],\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba Varias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos información de contexto del documento\n",
    "spacy.tokens.doc.Doc.set_extension('text_id' , default =False , force = True)\n",
    "doc_tuples = spacy_nlp.pipe([(\"Hola esto es una prueba que te parece\" , {\"text_id\" : \"text_id1_1\"})] , as_tuples=True , n_process=-1)\n",
    "docs = []\n",
    "\n",
    "for doc, context in doc_tuples:\n",
    "    doc._.text_id = context[\"text_id\"]\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    for token in doc:\n",
    "        print(f\"ddd.{token.text} {token.is_sent_start}  {token.lemma_} {token.norm_} {token.pos_}{doc._.text_id} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos-ayvd] *",
   "language": "python",
   "name": "conda-env-diplodatos-ayvd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
